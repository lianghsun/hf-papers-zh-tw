隨著模仿學習（IL）和大規模駕駛資料集的進步，端到端自動駕駛（E2E-AD）近期取得了重大進展。目前，基於 IL 的方法已成為主流範式：模型依賴於專家提供的標準駕駛行為，並學習最小化其行動與專家行動之間的差異。然而，這個「僅依照專家行駛」的目標存在泛化能力有限的問題：當遇到超出專家示範分佈的罕見或未見過的長尾場景時，在缺乏先前經驗的情況下，模型傾向於做出不安全的決策。這引發了一個根本性問題：E2E-AD 系統能否在沒有任何專家行動監督的情況下做出可靠的決策？受此啟發，我們提出了一個名為 Risk-aware World Model Predictive Control（RaWMPC）的統一框架，透過魯棒控制來解決這個泛化困境，而不依賴於專家示範。在實踐中，RaWMPC 利用世界模型來預測多個候選行動的後果，並透過明確的風險評估選擇低風險行動。為了賦予世界模型預測風險駕駛行為結果的能力，我們設計了一種風險感知的交互策略，系統性地將世界模型暴露於危險行為，使得災難性後果可預測，進而可以避免。此外，為了在測試時生成低風險的候選行動，我們引入了自評估蒸餾方法，將經過充分訓練的世界模型中的避風險能力蒸餾到一個生成式行動提案網絡中，無需任何專家示範。廣泛的實驗表明，RaWMPC 在分佈內和分佈外場景中都優於最先進的方法，同時提供了優越的決策可解釋性。