# 論文摘要翻譯

基於對大型語言模型中檢索頭（retrieval heads）的現有分析，我們提出了一個替代性的重排序框架，該框架訓練模型使用所選頭部的注意力分數來估計段落-查詢的相關性。這種方法提供了一個列表式解決方案，在排序過程中充分利用整個候選列表中的整體資訊。同時，它自然地產生連續的相關性分數，能夠在任意檢索資料集上進行訓練，無需依賴 Likert 量表監督。我們的框架輕量且有效，只需要小規模模型（例如 4B 參數）即可達到強大的性能。廣泛的實驗表明，我們的方法在多個領域（包括維基百科和長敘述資料集）上優於現有的最先進的逐點式和列表式重排序器。它進一步在 LoCoMo 基準上建立了新的最先進結果，該基準評估對話理解和記憶使用的能力。我們進一步展示了我們的框架支持靈活的擴展。例如，用上下文資訊增強候選段落進一步提高了排序準確性，而從中間層訓練注意力頭增強了效率，同時不犧牲性能。