# 論文摘要翻譯

大多數推薦系統基準測試評估模型模仿使用者行為的程度。然而，在金融顧問領域，觀測到的行為可能受到市場波動而產生雜訊或目光短淺，並且可能與使用者的長期目標相衝突。因此，將使用者的選擇視為唯一的真實標準會將行為模仿與決策品質混為一談。我們推出 Conv-FinRe，一個對話式和縱向的股票推薦基準測試，用於評估 LLM 超越行為匹配的能力。給定入門面談、逐步的市場背景和顧問對話，模型必須在固定的投資期限內生成股票排名。重要的是，Conv-FinRe 提供多視角參考，區分描述性行為與根植於投資者特定風險偏好的規範性效用，使我們能夠診斷 LLM 是否遵循理性分析、模仿使用者雜訊或受市場動量驅動。我們從真實市場數據和人類決策軌跡構建該基準測試，建立受控的顧問對話，並評估一套最先進的 LLM。研究結果揭示了理性決策品質與行為一致性之間的持久張力：在基於效用的排名上表現良好的模型通常無法匹配使用者選擇，而行為對齊的模型可能會過度擬合短期雜訊。該數據集已在 Hugging Face 上公開發布，程式碼庫可在 GitHub 上獲得。