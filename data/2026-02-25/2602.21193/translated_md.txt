# 關於縮放 LLM 終端能力的資料工程

儘管大語言模型的終端能力在近期取得快速進展，但最先進終端代理背後的訓練資料策略大多未被公開。我們透過對終端代理的資料工程實務進行系統性研究來解決這一空白，做出兩項關鍵貢獻：(1) Terminal-Task-Gen，一個輕量級合成任務生成管線，支援基於種子和技能的任務構建，以及 (2) 對資料和訓練策略的全面分析，包括過濾、課程學習、長文脈絡訓練和縮放行為。我們的管線產生了 Terminal-Corpus，一個大規模開源終端任務資料集。使用此資料集，我們訓練了 Nemotron-Terminal，一個從 Qwen3(8B, 14B, 32B) 初始化的模型系列，在 Terminal-Bench 2.0 上取得重大進展：Nemotron-Terminal-8B 從 2.5% 改進到 13.0%，Nemotron-Terminal-14B 從 4.0% 改進到 20.2%，Nemotron-Terminal-32B 從 3.4% 改進到 27.4%，達到與明顯更大模型相當的效能。為加速此領域的研究，我們在 https://huggingface.co/collections/nvidia/nemotron-terminal 開源了我們的模型檢查點和大部分合成資料集。

[FIGURE:data_pipeline.png] 圖 1：Terminal-Task-Gen 的概觀。我們的框架結合了資料集調適（將現有基準轉換為終端提示）和合成任務生成（使用種子資料和技能分類法來構建目標場景）。來自兩個流的任務在軌跡生成階段被利用，其中代理與 Docker 化環境互動以產生解決方案軌跡，隨後進行後處理（去污染和過濾）以產生最終 SFT 資料集。

## 1 介紹

隨著大型語言模型（LLMs）向實際軟體工程應用發展，終端機互動已成為一項關鍵能力。像 Claude Code（Anthropic, 2025a）和 Codex CLI（OpenAI, 2025a）這樣的工具展示了命令列熟練度的潛力，前沿模型在 Terminal-Bench（Merrill et al., 2026）等基準測試上顯示出令人矚目的成果。然而，這些系統背後的訓練資料混合方案在很大程度上仍未公開，使得有關有效資料設計的基本問題無法得到解答。這種缺乏透明度的情況迫使研究人員進入成本高昂的試錯過程，主要源於智能體資料生成中的兩個重大瓶頸：(1) 基礎資源的稀缺性，包括多樣化的任務提示、必要的相依性檔案和預先配置的環境；(2) 軌跡收集的後勤複雜性，因為實際的人類互動難以捕捉，而透過 LLM 智能體的合成生成則由於需要為每個任務進行新的環境實例化和多輪互動而成本過高。

表 1：Terminal-Bench 2.0 上的模型效能比較。

改進終端機能力的當前方法主要分為兩大類：改進智能體框架（Singhal et al., 2025；Antigma, 2025；JetBrains, 2025；Internet, 2025；Nichols, 2025；Mux, 2025；Letta, 2025）或改進用於終端機應用的底層模型（OpenAI, 2025b；DeepMind, 2025；Anthropic, 2025b；Liu et al., 2025；Moonshot AI, 2025；MiniMax, 2025）。後訓練模型的一個著名方法涉及使用適配器，將現有資料集包裝在命令列介面中（Development, 2025a、b；DCAgent, 2025）。雖然 Terminal-Bench 的作者提供了此類適配器的儲存庫（Team, 2025a），主要用於基準測試適應，但這些適配器也可以重新用途作為擴展訓練資料的起點。然而，適配器繼承了源資料集的結構假設，這些資料集從未為順序環境互動而設計，可能限制其有效性。最近的工作探索了多智能體框架（Austin, 2025；Peng et al., 2025）以進行更有原則的資料生成，但這些方法引入了在大規模訓練中擴展性不佳的計算複雜性。因此，該領域缺乏一個實用的框架，能夠平衡生成效率與訓練有效終端機智能體的特定要求。

我們通過結合資料集適應與合成任務生成的雙重策略方法來解決這一差距。資料集適應透過將現有的數學、程式碼和軟體工程資料集轉換為 Terminal-Bench 格式，提供廣泛覆蓋，同時利用高品質的問題來源高效地擴展資料量。合成任務生成提供更精細的控制：它能夠開發終端機特定技能，並可控制任務特性，如難度、領域覆蓋和基本技能組成。這些策略是互補的，並解決了不同的瓶頸：適配器透過充分利用現有資料集來大規模建立基礎終端機能力，而合成任務生成提供了靈活性來針對特定能力差距。基於這一從粗到細的資料生成管線，我們開發了 Nemotron-Terminal，這是一個從 Qwen3 模型（Yang et al., 2025a）進行微調的模型系列。

具體來說，我們做出了以下貢獻：

- 1. 我們引入了 Terminal-Task-Gen，一個可擴展的合成任務生成管線，能夠快速探索任務設計並針對具有不同難度級別的特定技能進行有針對性的生成。
- 2. 我們進行了資料工程策略的系統研究，考查了資料集適配器和合成任務的過濾策略、資料混合的課程學習、長上下文訓練和擴展趨勢。
- 3. 我們進行了廣泛的實驗來驗證我們所策劃資料集的有效性。如表 1 所示，在 Terminal-Bench 2.0 上，我們的模型相對於初始的 Qwen3 基線實現了實質性的改進，達到與明顯更大的模型相競爭的效能，同時只需要適度的計算資源進行訓練和推論。例如，我們的 Nemotron-Terminal-32B 在 Terminal-Bench 2.0 上超過了 Qwen3-Coder-480B（Yang et al., 2025a）（27.4 ± 2.4 vs. 23.9 ± 2.8）。我們在 https://huggingface.co/collections/nvidia/nemotron-terminal 上發佈了 Nemotron-Terminal 模型和 Terminal-Corpus 資料集。

我們引入了 Terminal-Task-Gen，一個可擴展的合成任務生成管線，能夠快速探索任務設計並針對具有不同難度級別的特定技能進行有針對性的生成。

我們進行了資料工程策略的系統研究，考查了資料集適配器和合成任務的過濾策略、資料混合的課程學習、長上下文訓練和擴展趨勢。

我們進行了廣泛的實驗來驗證我們所策劃資料集的有效性。如表 1 所示，在 Terminal-Bench 2.0 上，我們的模型相對於初始的 Qwen3 基線實現了實質性的改進，達到與明顯更大的模型相競爭的效能，同時只需要適度的計算資源進行訓練和推論。例如，我們的 Nemotron-Terminal-32B 在 Terminal-Bench 2.0 上超過了 Qwen3-Coder-480B（Yang et al., 2025a）（27.4 ± 2.4 vs. 23.9 ± 2.8）。我們在 https://huggingface.co/collections/nvidia/nemotron-terminal 上發佈了 Nemotron-Terminal 模型和 Terminal-Corpus 資料集。

## 2 相關工作

**代理設計**

如 Claude Code（Anthropic, 2025a）和 Codex CLI（OpenAI, 2025a）所示，複雜的代理架構可以顯著提升性能。許多領先的終端代理通過架構創新實現了前沿性能（Singhal et al., 2025；Antigma, 2025；JetBrains, 2025；Internet, 2025；Nichols, 2025；Mux, 2025；Letta, 2025）。然而，有效的代理架構往往對特定模型具有針對性，需要大量工程工作。隨著基礎模型的進步，複雜架構的邊際收益可能會下降。相比於探索代理設計的變體，我們專注於透過有針對性的有監督微調來擴展基礎模型的能力。

**數據集適配器**

Hugging Face 上的多個數據集（Development, 2025a, b；DCAgent, 2025）透過在終端環境中展開來自現有數據集的提示，收集代理執行跟蹤。這種方法可以透過重複使用來自不同領域（包括競爭編碼和數學）的現有提示，有效地擴展數據收集。儘管這些數據集數量豐富，但尚無正式分析研究過數據集適配器的哪些特徵會影響下游訓練的有效性。在本工作中，我們透過使用自訂數據集和適配器的系統研究，探索了這種方法的優缺點。

**合成任務生成**

許多研究已經探討如何有效地為 LLM 微調生成合成數據。Evol-Instruct（Xu et al., 2023）開創了透過迭代式深度和廣度演化進行自動化指令數據擴展。Code Evol-Instruct（Luo et al., 2023）成功地將此策略適配用於自動增加代碼指令數據的複雜度，以進行有效微調。此後，AgentInstruct（Mitra et al., 2024）和 LAB（Sudalairaj et al., 2024）已經展示了如何透過建議者-編輯者代理對和基於分類法的生成，從現有種子數據生成大規模數據集。其他工作如 MAGPIE（Xu et al., 2024）已經探討了不使用種子數據，透過獨特的提示策略從對齊的 LLM 中提取指令數據。

近期工作已探討將這些想法應用於 LLM 的終端能力擴展，採用多代理系統來進行思想腦力激盪、生成任務、設計 Docker 環境，以及驗證生成的任務和環境（Austin, 2025；Peng et al., 2025）。由於多代理系統可能耗時且成本高昂，我們設計了一個簡化系統，消除不必要的協調階段並最佳化環境驗證，以實現有效的擴展。透過我們的系統研究和消融實驗，我們為擴展終端功能模型提供了可行的洞見。

## 3 背景

### 3.1 Terminal-Bench

Terminal-Bench (Merrill et al., 2026 ; Team, 2025b ) 已成為在終端環境中評估代理的標準基準。該基準包含 89 個手工製作、經人工驗證的任務，涵蓋科學計算、軟體工程、機器學習、安全性、系統管理和資料科學等多個領域。與評估孤立函數的傳統程式碼生成基準不同，Terminal-Bench 任務要求代理完成端到端工作流程，例如編譯程式碼、訓練模型、配置系統和調試環境。

如圖 3 所示，Terminal-Bench 中的每個任務包含四個元件：(1) 描述目標的自然語言指令、(2) 提供執行環境的容器化 Docker (Merkel, 2014 ) 環境、(3) 以程式化方式檢查任務完成情況的驗證測試套件，以及 (4) 展示有效方法的預言解決方案。在整個工作中，我們使用 Terminal-Bench 2.0 作為主要評估基準，並利用隨基準一起發佈的模型無關參考代理 Terminus 2，在模型檢查點之間進行一致的評估。

Figure 2: Terminal-Bench 任務目錄結構。每個任務包含指令提示、任務元資料、環境檔案、Dockerfile、參考解決方案和測試案例。

### 3.2 Terminus 2 代理框架

與提供多個專門工具的傳統編碼代理不同，Terminus 2 (Team, 2025b ) 僅提供在沙箱 Docker (Merkel, 2014 ) 容器內執行的互動式 tmux 工作階段。通過向 tmux 工作階段發送模型決定的按鍵，代理具有使用任何可用命令列工具來處理任務的靈活性。

在每個步驟中，代理接收目前的終端輸出，並提示模型以結構化的 JSON 格式（圖 3）進行回應，該格式決定了發送至環境的下一個動作。

## 4 合成資料生成

為終端環境訓練自主代理需要一種系統化的資料管理方法，平衡廣度、深度和可擴展性。我們介紹一個有原則的兩階段資料生成框架：資料集適應以建立廣泛的基礎涵蓋，隨後是合成任務生成以進行有針對性的技能精化。這種粗到細的策略將資料量縮放與任務設計迭代解耦：適配器有效地利用現有問題庫來建立一般能力，而合成生成則能對技能組成、難度進度和領域特定要求進行精確控制。這些互補策略共同產生了多樣化、高品質的監督微調 (SFT) 資料集，系統性地涵蓋終端問題解決所需的操作和計算技能。

### 4.1 資料集適配器

#### 4.1.1 提示資料集

我們有針對性地識別涵蓋數學、程式碼和軟體工程（SWE）領域的高品質 SFT 提示資料集，因為這些領域是終端使用涵蓋主題的基礎。

數學提示。

我們使用 Nemotron-Cascade 的數學推理 SFT 資料中的第 2 階段提示集合（Wang et al., 2025），該集合包含從 OpenMathReasoning（Moshkov et al., 2025）提取的 163K 個獨特提示。為了獲得這個高品質提示集合，Nemotron-Cascade 通過排除 DeepSeek-R1（Guo et al., 2025）回應長度短於 2K tokens 的提示來過濾掉原始資料集中的簡單問題。

程式碼提示。

我們使用 Nemotron-Cascade 的程式碼推理 SFT 資料中的第 2 階段提示集合，該集合包含來自 OpenCodeReasoning（Ahmad et al., 2025）的 79K 個提示，涵蓋具有挑戰性的程式碼問題。我們進一步過濾和去重此集合，得到 35K 個提示的子集。

軟體工程提示。

對於軟體工程任務，我們從 Nemotron-Cascade 的 SWE 程式碼修復 SFT 資料中提取，該資料包含來自 SWE-Bench-Train（Jimenez et al., 2023）、SWE-reBench（Badertdinov et al., 2025）、SWE-Smith（Yang et al., 2025b）和 SWE-Fixer-Train（Xie et al., 2025）的 127K 個實例。每個提示都包含問題陳述和一個或多個有缺陷的程式碼檔案的內容。我們進一步過濾和去重此集合，得到 32K 個獨特提示。

#### 4.1.2 適配器格式

資料集適配是一個直接的過程，它將現有的提示資料集轉換為 Terminal-Bench 格式，無需在迴圈中使用 LLM。使用 Terminus 2 系統提示範本（附錄 A.2），我們將每個條目映射到 { instruction } 佔位符，並根據資料集類型附加唯一的指令後綴。用於數學、程式碼和 SWE 提示的特定後綴詳見附錄 A.2。對於 SWE 提示中識別的每個程式碼檔案，我們在環境中實例化相應的檔案。由於 Nemotron-Cascade 資料集僅提供提示，這些任務包含指令和環境，不含相關的測試案例。

### 4.2 合成任務生成

雖然資料集適配器提供了推理和程式碼的基礎廣度，但它們本質上受限於其原始儲存庫的格式。為了橋接一般問題求解與終端代理的特定嚴格要求之間的差距，我們引入了 Terminal-Task-Gen，一個合成管道，能以精確控制技能複雜度和環境約束來生成可執行的任務。透過從結構化種子和原始技能分類法生成任務，我們確保訓練資料直接反映終端代理所需的操作細節和多步驟工具交互。

我們提出了兩種互補的方法來生成合成終端操作任務：基於種子的生成和基於技能的生成。兩種方法都利用 LLM 來生成多樣化、可執行的終端任務，同時解決可擴展性、多樣性和領域覆蓋的不同需求。

#### 4.2.1 從種子資料生成

基於種子的生成透過將現有問題作為靈感而非固定模板，來補充資料集適配。我們不是將原始提示包裝在終端框架中，而是提示 LLM 從種子問題合成新的終端任務。這種方法對於利用相鄰領域的高品質問題規範特別有效，例如科學計算挑戰、演算法問題集或領域特定的程式碼練習，這些領域存在定義完善的問題，但缺乏代理訓練所需的終端導向任務結構。

種子資料結構。

每個種子條目都是包含以下內容的結構化記錄：(1) 指定計算挑戰的問題描述，(2) 指示科學或技術領域的可選網域標籤（例如，生物學、物理學、最佳化），以及 (3) 提供正確實現的可選參考解決方案。參考解決方案（如果可用）用作生成測試期望的真實性資料，但絕不會暴露給代理。

任務適配。

LLM 充當任務適配器，將每個種子問題轉換為自包含的終端任務。這種轉換涉及幾個關鍵操作。首先，抽象問題陳述被擴充為具體的軟體工程需求：代理必須安裝必要的套件、從指定的檔案路徑讀取輸入、實現解決方案，並將結果寫入指定的輸出位置。其次，適配器生成具體化特定測試案例的現實輸入資料檔案，包括邊界情況和邊界條件。第三，合成基於 pytest 的綜合測試案例來驗證正確性，其檢查輸出檔案存在性、格式合規性、數值精度（對於浮點結果使用適當的容差）和邊界情況處理。當參考解決方案在種子資料中提供時，它包含在生成內容中，提示指示 LLM 在設計測試案例時將其用作真實性資料。

轉換準則。

轉換提示編碼了多項原則以確保任務品質：複雜問題在必要時被分解為可驗證的單位；實際約束（例如輸入大小和精度需求）被添加以將問題基於現實場景；輸出格式的設計目的是實現無歧義的程式化驗證。這種系統適配使管道能夠將多樣化的問題來源轉換為適合代理評估的統一任務格式。

#### 4.2.2 從原始技能生成

基於技能的生成採取了根本不同的方法：不是適配現有問題，而是從原始終端操作技能的結構化分類法合成新穎的任務規範。我們整理了原始終端操作技能的列表，並採用 LLM 來擴展和重組這些原始元素進入創意任務規範。

領域特定生成。

任務生成過程本質上是特定領域的。我們定義了 9 個任務領域：資料處理、資料查詢、資料科學、除錯、相依性管理、檔案操作、科學計算、安全性和軟體工程。每個領域都與專用的生成提示相關聯，該提示引導 LLM 生成與領域焦點領域相符的任務。例如，資料科學提示指導模型朝向涉及統計分析和資料轉換的任務，而安全性提示強調密碼操作和存取控制驗證。這種領域感知的提示確保生成的任務展現連貫的主題焦點，同時練習適合目標類別的技能。

技能分類法。

在每個領域中，原始技能被收集並跨越終端問題求解的多個維度：(1) 演算法技能，例如圖形遍歷、約束滿足和回溯搜尋；(2) 系統技能，包括檔案 I/O、流程管理和網路配置；(3) 資料處理技能，例如解析、序列化和轉換管道；(4) 數學技能，包括數值積分和統計模型化；(5) 測試技能，例如驗證、驗証和基準測試；以及 (6) 網路/安全性技能，包括 HTTP 處理、認證和漏洞分析。每個領域的技能總結在附錄中。

組合任務合成。

LLM 被指示以非平凡的方式組合多個原始元素（通常每個任務 3–5 項技能），生成需要整合問題求解而非孤立技能應用的任務。至關重要的是，生成提示強調新穎性：模型被引導創造新情景，從而最大化生成任務的多樣性和覆蓋範圍。

#### 4.2.3 任務格式和執行環境

兩種生成方法都生成標準化格式的任務，包括：(1) 指定目標和約束的自然語言任務提示，(2) 具有可配置部分信用權重的基於 pytest 的測試案例，(3) 提供必要資料的補充輸入檔案，以及 (4) 用於一致執行的領域特定 Docker 環境。檔案的結構方式與 Terminal-Bench 相同，如圖 3 所示。

請注意，我們不生成 oracle 解決方案，因為在沒有人工驗證的情況下生成真實程式碼會非常困難；相反，我們生成易於驗証但難以求解的任務，並使用合成測試案例來評估代理解決方案的正確性。

解決方案隔離。

在所有生成提示中強制執行的關鍵設計原則是問題規範與解決方案資訊之間的分離。所有提示都明確指示 LLM 避免解決方案洩漏：代理可見的任務提示必須不洩露演算法、實現方法或任何解決問題的程式碼。當參考解決方案可用時（例如在種子資料中），它們僅用於推導真實性測試期望。這確保生成的任務需要問題求解而非簡單的解決方案檢索。

預先建置的 Docker 映像。

實現大規模任務生成的關鍵設計決策是使用預先建置、領域特定的 Docker 映像。我們不像以前的工作（Austin, 2025；Peng et al., 2025）那樣為每個任務生成唯一的 Dockerfile，而是維護一組固定的領域特定 Docker 映像，每個映像都預先安裝該領域內通常需要的套件和相依性（例如，用於資料科學的 pandas 和 scikit-learn；用於安全性的密碼庫）。

這種方法提供了三個可擴展性優勢。首先，它消除了 Dockerfile 驗証開銷；透過避免每個任務環境生成通常需要的成本高昂的多轉修復，預先建置的映像實現了高效的單次通過任務建立。其次，它減少了資源足跡，僅使用 9 個共享基礎映像，而不是建置和快取數千個唯一容器。第三，它解耦了環境和任務生成，允許管道在穩定的環境中生成多樣化的情景，同時保留代理安裝執行時相依性的靈活性。

### 4.3 教師模型

我們選擇 DeepSeek-V3.2（Liu et al., 2025）作為我們的教師模型來生成合成任務和軌跡，這是由於其在 Terminal-Bench 2.0 上的強大性能（表 3）所驅動的。為了進一步驗證其生成數據集適配器軌跡的適用性，我們使用 Terminus 2 代理框架在幾個標準基準上評估 DeepSeek-V3.2（表 2），這些基準已適配為 Terminal-Bench 格式，包括 AIME 2024（MAA, 2024）、AIME 2025（MAA, 2025）、LiveCodeBench v6（Jain et al., 2024）和 SWE-bench Verified（Jimenez et al., 2023；OpenAI, 2024）。

表 2：DeepSeek-V3.2 在適配數學、編碼和 SWE 基準上的性能。使用 Terminus 2 代理，我們在適配為 Terminal-Bench 格式的 AIME、LiveCodeBench 和 SWE-bench Verified 上評估 DeepSeek-V3.2，我們發現即使在此基於終端的設置下，它的表現也相當不錯。

### 4.4 數據篩選

我們首先通過移除與 Terminal-Bench 2.0 測試樣本有 14-gram 重疊的任何提示來清除我們的 SFT 數據集的污染。然後，我們應用各種品質篩選，包括移除身份洩露和丟棄包含中文字符的回應。

除了品質篩選外，我們還嘗試移除教師模型生成的不完整軌跡，以防止微調後的模型變得過度冗長。當測試可用時，我們進一步嘗試只保留通過測試的軌跡。

## 5 實驗

### 5.1 實驗設置

**基礎模型。** 我們使用來自 Qwen3 族群的預訓練模型進行實驗（Yang et al., 2025a）。我們使用 Qwen3-8B 作為進行消融研究的主要模型，並額外實驗 Qwen3-14B 和 Qwen3-32B 以驗證我們的發現能隨著模型大小縮放。

表 3：使用 Terminus 2 agent 的 Terminal-Bench 2.0（TB2.0）結果。

**訓練細節。** 除非另有說明，我們使用以下訓練超參數：學習率 2e-5、權重衰減 1e-4、2 個 epoch、最大序列長度 32,768 token、全局批次大小 128、每個 GPU 的微批次大小 1，採用 AdamW 優化器（β = 0.9, 0.95）、10% 預熱的余弦學習率排程器，以及梯度裁切設為 1.0。8B 和 14B 模型在 4 個節點上訓練，每個節點 8 個 GPU（共 32 個 GPU），使用序列並行度 2。32B 模型在 16 個節點上訓練（共 128 個 GPU）。所有實驗都使用 CPU 卸載。

**基礎設施。** 我們利用 Harbor（Shaw, 2025）─ 來自 Terminal-Bench 2.0 的基礎設施框架（Team, 2025b）─ 在容器化環境中協調大規模軌跡生成。我們擴展 Harbor 以支持 Singularity（Kurtzer et al., 2017），使其能在 HPC 叢集上部署；雖然這因 fakeroot overlay 限制而引入罕見的失敗，但這些對於合成資料生成而言是可接受的。對於評估，我們依賴 Daytona（Daytona, 2025）在隔離的雲端沙箱中管理可靠的平行執行。

對於 SFT 實驗，我們使用 veRL（Sheng et al., 2024），一個為高效 LLM 訓練而設計的開源框架。

### 5.2 主要結果

我們透過在 Terminal-Bench 2.0（TB2.0）上對 Nemotron-Terminal 進行基準測試來評估 Terminal-Task-Gen。如表 3 所示，我們的模型展示出實質性的進展：Nemotron-Terminal-8B 達到 $13.0 \pm 2.2$，相比 Qwen3-8B（$2.47 \pm 0.5$）增加了五倍。值得注意的是，儘管規模相對較小，它們與規模大得多的系統相當；Nemotron-Terminal-14B（$20.2 \pm 2.7$）優於 120B 的 GPT-OSS（$18.7 \pm 2.7$）和 Gemini 2.5 Flash（$16.9 \pm 2.4$），而 Nemotron-Terminal-32B（$27.4 \pm 2.4$）則優於 480B 的 Qwen3-Coder（$23.9 \pm 2.8$）。這驗證了高品質軌跡資料能有效地縮小效率模型和大型前沿模型之間的差距。

按任務類別進行的進一步分析（表 4）確認了我們的合成資料在基礎模型全面失效的關鍵能力上進行了解鎖。雖然 Qwen3-14B 和 32B 模型在資料查詢和模型訓練中均得分 0.0，但 Nemotron-Terminal-32B 分別躍升至 60.0 和 50.0，代表著功能性實用程度的重大飛躍。類似的轉變也出現在安全性（2.5 至 27.5）、資料處理（5.0 至 50.0）和軟體工程（5.0 至 31.7）中（32B 變體），表明單純的參數數量增加不足以實現強大的終端機能力。此外，系統管理（6.7 至 31.1）和除錯（0.0 至 33.3）的持續進展表明，我們的方法成功地灌輸了特定領域的技能——例如複雜的檔案操作和命令列疑難排解，這些在原始模型中基本上不存在。

表 4：模型按 Terminal-Bench 類別的效能。Qwen3 和 Nemotron-Terminal 模型的 TB2.0 分數，按類別細分，顯示 Nemotron-Terminal 相比 Qwen3 基準線最大程度改進的地方。

表 5：Qwen3-8B 監督微調結果跨訓練資料來源。我們展示了從各種子集訓練得到的樣本總數和 TB2.0 結果。對於資料集適配器和合成任務，我們從結合所有資料來源中達到最強結果。

### 5.3 資料集組件消融實驗

如表 6 所示，每個資料來源都提供了補充性的價值。對於資料集適配器，雖然數學（5.39%）和程式碼（6.29%）等個別分割相比 SWE（7.02%）表現欠佳，但將它們結合起來會導致效能顯著躍升至 9.66%，確認了合併不同領域比任何單一來源都能產生進一步改進。類似的穩健性模式也出現在合成任務中，其中基於技能的資料驅動了主要增益（12.4%）；雖然添加基於種子的資料不會增加平均分數，但它成功地降低了方差，使模型更加穩健。

### 5.4 過濾策略

軌跡過濾

我們調查了第 4.4 節中討論的幾種軌跡過濾策略。對於資料集適配器（表 6），雖然我們在各子集上觀察到沒有顯著差異，但無過濾設定在完整集合上產生最高效能（9.66%），因此被採用。對於合成任務（表 8），影響更加顯著：無過濾（12.4%）明顯超越完整軌跡過濾（6.74%）和僅成功軌跡過濾（5.06%）策略。這個效能差距表明嚴格過濾是有害的，因為它會丟棄超過一半的可用訓練資料。此外，保留失敗的軌跡似乎提供了寶貴的監督信號，讓模型能夠接觸現實的錯誤狀態和恢復模式，從而增強整體穩健性。

表 7：Qwen3-8B 在合成任務過濾上的消融實驗。在合成任務子集上，我們實驗無過濾、完整軌跡過濾和僅成功軌跡過濾。無過濾產生明顯更佳的效能。

### 5.5 長文本上下文訓練與評估

終端軌跡的回合數量差異很大（附錄 A.1），進而根據任務類型和難度導致 token 計數的巨大差異。如附錄 A.1 所示，大多數軌跡都符合 Qwen3 模型的預設最大序列長度（32,768 tokens），但一個非平凡的子集超過此限制，在監督微調時被截斷。基於這一動機，我們針對 Qwen3-8B 調查長文本上下文訓練。

具體而言，我們比較了具有 65,536-token 上下文窗口但不使用 YaRN2（Peng et al., 2023）的監督微調、具有 YaRN2 的監督微調，以及僅在評估時應用 YaRN2 的基準。在這些設定中，我們觀察到沒有顯著的效能差異（表 8）。此外，在標準 Qwen3-8B 設定下使用 40,960-token 上下文窗口進行評估產生更強的結果。我們的結果表明擴展上下文長度會輕微傷害效能；大多數高品質監督已經符合標準窗口，而長尾軌跡往往雜訊多且資訊量少。

### 5.6 課程學習

我們調查了兩種用於資料混合的監督微調課程策略：(1) 兩階段課程，我們首先在資料集適配器上訓練，然後進行合成任務資料訓練；以及 (2) 單階段策略，我們在所有資料集上同時訓練。如表 9 所示，兩階段課程相比簡單混合訓練沒有效能優勢。因此，我們在本論文的所有其他實驗中採用單階段混合訓練策略。

[FIGURE:scaling_results.png] 圖 4：訓練資料規模對模型效能的影響。我們的縮放實驗顯示 TB2.0 效能隨著 Qwen3-8B 和 Qwen3-14B 的訓練資料量增加而提升。

### 5.7 縮放實驗

我們透過在不同百分比的合成訓練數據（0%、1%、2%、5%、10% 和 100%）上微調 Qwen3-8B 和 Qwen3-14B 模型，來調查訓練數據規模對模型性能的影響。兩個模型都表現出隨著訓練數據增加而持續改進的性能（圖 4）。較大的 14B 模型不僅在所有數據規模上達到更高的絕對性能，而且從額外訓練數據中獲得更大的收益。這些結果證明了模型容量和訓練數據規模都是性能的關鍵因素。

## 6 結論

在這項工作中，我們透過引入 Terminal-Task-Gen 來解決終端代理訓練中的數據稀缺瓶頸，這是一個可擴展的框架，融合了大規模數據集自適應與針對性合成任務生成。我們的系統性研究表明，精確的數據工程使高效的 Nemotron-Terminal 家族能夠在 Terminal-Bench 2.0 上顯著超越其 Qwen3 基礎模型，並與更大型的前沿模型相匹敵，證明了高質量、多樣化的軌跡比純粹的參數規模更為關鍵。展望未來，我們看到透過強化學習（RL）擴展這一基礎具有重大潛力，利用可驗證的執行反饋來實現自我修正和長時間地平線任務的最優規劃。我們發布了我們的模型和大部分合成數據集，包括適配器和基於技能的任務子集，以民主化自主終端代理的研究。

## 參考文獻

- Ahmad et al. (2025) Wasi Uddin Ahmad, Sean Narenthiran, Somshubra Majumdar, Aleksander Ficek, Siddhartha Jain, Jocelyn Huang, Vahid Noroozi, and Boris Ginsburg. Opencodereasoning: Advancing data distillation for competitive coding. arXiv preprint arXiv:2504.01943 , 2025.
- Anthropic (2025a) Anthropic. Claude code: Best practices for agentic coding. https://www.anthropic.com/engineering/claude-code-best-practices , 2025年4月.
- Anthropic (2025b) Anthropic. Introducing claude opus 4.5. https://www.anthropic.com/news/claude-opus-4-5 , 2025b.
- Antigma (2025) Antigma. Meet ante. https://antigma.ai/ , 2025.
- Austin (2025) Dan Austin. Terminal bench agentic data pipeline. https://github.com/Danau5tin/tbench-agentic-data-pipeline , 2025.
- Badertdinov et al. (2025) Ibragim Badertdinov, Alexander Golubev, Maksim Nekrashevich, Anton Shevtsov, Simon Karasik, Andrei Andriushchenko, Maria Trofimova, Daria Litvintseva, and Boris Yangel. Swe-rebench: An automated pipeline for task collection and decontaminated evaluation of software engineering agents. arXiv preprint arXiv:2505.20411 , 2025.
- Daytona (2025) Daytona. Daytona cloud: Secure and elastic infrastructure for running your AI-generated code. https://www.daytona.io , 2025.
- DCAgent (2025) DCAgent. bash_textbook_tasks_traces. https://huggingface.co/datasets/DCAgent/bash_textbook_tasks_traces , 2025.
- DeepMind (2025) Google DeepMind. A new era of intelligence with gemini 3. https://blog.google/products-and-platforms/products/gemini/gemini-3/ , 2025.
- Development (2025a) ML Foundations Development. staqc-sandboxes-traces-terminus-2. https://huggingface.co/datasets/mlfoundations-dev/staqc-sandboxes-traces-terminus-2 , 2025a.
- Development (2025b) ML Foundations Development. code-contests-sandboxes-traces-terminus-2. https://huggingface.co/datasets/mlfoundations-dev/code-contests-sandboxes-traces-terminus-2 , 2025b.
- Guo et al. (2025) Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. arXiv preprint arXiv:2501.12948 , 2025.
- Internet (2025) Intelligent Internet. Ii-agent. https://ii.inc/web/blog/post/ii-agent , 2025.
- Jain et al. (2024) Naman Jain, King Han, Alex Gu, Wen-Ding Li, Fanjia Yan, Tianjun Zhang, Sida Wang, Armando Solar-Lezama, Koushik Sen, and Ion Stoica. Livecodebench: Holistic and contamination free evaluation of large language models for code. arXiv preprint arXiv:2403.07974 , 2024.
- JetBrains (2025) JetBrains. Junie cli: Llm-agnostic coding agent built for real-world development. https://junie.jetbrains.com/ , 2025.
- Jimenez et al. (2023) Carlos E Jimenez, John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei, Ofir Press, and Karthik Narasimhan. Swe-bench: Can language models resolve real-world github issues? arXiv preprint arXiv:2310.06770 , 2023.
- Kurtzer et al. (2017) Gregory M. Kurtzer, Vanessa Sochat, and Michael W. Bauer. Singularity: Scientific containers for mobility of compute. PloS One , 12(5):e0177459, 2017. 10.1371/journal.pone.0177459 .
- Letta (2025) Letta. Building the #1 open-source terminal-use agent using letta. https://www.letta.com/blog/terminal-bench , 2025.
- Liu et al. (2025) Aixin Liu, Aoxue Mei, Bangcai Lin, Bing Xue, Bingxuan Wang, Bingzheng Xu, Bochao Wu, Bowei Zhang, Chaofan Lin, Chen Dong, et al. Deepseek-v3. 2: Pushing the frontier of open large language models. arXiv preprint arXiv:2512.02556 , 2025.
- Luo et al. (2023) Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma, Qingwei Lin, and Daxin Jiang. Wizardcoder: Empowering code large language models with evol-instruct. arXiv preprint arXiv:2306.08568 , 2023.
- MAA (2024) MAA. Aime 2024 benchmark: Problems from the american invitational mathematics examination. https://huggingface.co/datasets/Maxwell-Jia/AIME_2024 , 2024. 用於評估語言模型中數學推理能力的 AIME 2024 問題基準。
- MAA (2025) MAA. Aime 2025 benchmark: Problems from the american invitational mathematics examination. https://ukgovernmentbeis.github.io/inspect_evals/evals/mathematics/aime2025/ , 2025. 用於評估語言模型中數學推理能力的 AIME 2025 問題基準。
- Merkel (2014) Dirk Merkel. Docker: lightweight linux containers for consistent development and deployment. In Linux Journal , number 239. Belltown Media, 2014.
- Merrill et al. (2026) Mike A Merrill, Alexander G Shaw, Nicholas Carlini, Boxuan Li, Harsh Raj, Ivan Bercovich, Lin Shi, Jeong Yeon Shin, Thomas Walshe, E Kelly Buchanan, et al. Terminal-bench: Benchmarking agents on hard, realistic tasks in command line interfaces. arXiv preprint arXiv:2601.11868 , 2026.
- MiniMax (2025) MiniMax. Minimax m2 & agent: Ingenious in simplicity. https://www.minimax.io/news/minimax-m2 , 2025.
- Mitra et al. (2024) Arindam Mitra, Luciano Del Corro, Guoqing Zheng, Shweti Mahajan, Dany Rouhana, Andres Codas, Yadong Lu, Wei-ge Chen, Olga Vrousgos, Corby Rosset, et al. Agentinstruct: Toward generative teaching with agentic flows. arXiv preprint arXiv:2407.03502 , 2024.
- Moonshot AI (2025) Moonshot AI. Introducing kimi k2 thinking. https://moonshotai.github.io/Kimi-K2/thinking.html , 2025年11月.
- Moshkov et al. (2025) Ivan Moshkov, Darragh Hanley, Ivan Sorokin, Shubham Toshniwal, Christof Henkel, Benedikt Schifferer, Wei Du, and Igor Gitman. Aimo-2 winning solution: Building state-of-the-art mathematical reasoning models with openmathreasoning dataset. arXiv preprint arXiv:2504.16891 , 2025.
- Mux (2025) Mux. Terminal benchmarking. https://mux.coder.com/reference/benchmarking , 2025.
- Nichols (2025) Jack Nichols. How we scored #1 on terminal-bench (52%). https://www.warp.dev/blog/terminal-bench , 2025.
- OpenAI (2024) OpenAI. Introducing swe-bench verified. https://openai.com/index/introducing-swe-bench-verified/ , 2024年8月.
- OpenAI (2025a) OpenAI. Introducing codex. https://openai.com/index/introducing-codex/ , 2025年5月. Codex 編碼代理的概述，可透過 ChatGPT 和相關客戶端存取。
- OpenAI (2025b) OpenAI. Introducing gpt-5.2. https://openai.com/index/introducing-gpt-5-2/ , 2025b.
- Peng et al. (2023) Bowen Peng, Jeffrey Quesnelle, Honglu Fan, and Enrico Shippole. Yarn: Efficient context window extension of large language models. arXiv preprint arXiv:2309.00071 , 2023.
- Peng et al. (2025) Xiaoxuan Peng, Xinyu Lu, Kaiqi Zhang, Taosong Fang, Boxi Cao, and Yaojie Lu. Litecoder-terminal: Lightweight terminal agents with <1k synthesized trajectories. https://huggingface.co/blog/Lite-Coder/litecoder-terminal-preview , 2025.
- Shaw (2025) Alex Shaw. Harbor Framework, 2025年11月. URL https://github.com/laude-institute/harbor .
- Sheng et al. (2024) Guangming Sheng, Chi Zhang, Zilingfeng Ye, Xibin Wu, Wang Zhang, Ru Zhang, Yanghua Peng, Haibin Lin, and Chuan Wu. Hybridflow: A flexible and efficient RLHF framework. arXiv preprint arXiv: 2409.19256 , 2024.
- Singhal et al. (2025) Abhay Singhal, Leo Tchourakov, Daniel Flaherty, and Stepan Bedratiuk. Droid: The #1 software development agent on terminal-bench. Factory AI News , 2025年9月. URL https://factory.ai/news/terminal-bench .
- Sudalairaj et al. (2024) Shivchander Sudalairaj, Abhishek Bhandwaldar, Aldo Pareja, Kai Xu, David D Cox, and Akash Srivastava. Lab: Large-scale alignment for chatbots. arXiv preprint arXiv:2403.01081 , 2024.
- Team (2025a) The Terminal-Bench Team. Adapters. https://harborframework.com/docs/adapters , 2025a.
- Team (2025b) The Terminal-Bench Team. Terminal-bench: A benchmark for ai agents in terminal environments, 2025年4月. URL https://github.com/laude-institute/terminal-bench .
- Wang et al. (2025) Boxin Wang, Chankyu Lee, Nayeon Lee, Sheng-Chieh Lin, Wenliang Dai, Yang Chen, Yangyi Chen, Zhuolin Yang, Zihan Liu, Mohammad Shoeybi, et al. Nemotron-cascade: Scaling cascaded reinforcement learning for general-purpose reasoning models. arXiv preprint arXiv:2512.13607 , 2025.
- Xie et al. (2025) Chengxing Xie, Bowen Li, Chang Gao, He Du, Wai Lam, Difan Zou, and Kai Chen. Swe-fixer: Training open-source LLMs for effective and efficient GitHub issue resolution. arXiv preprint arXiv:2501.05040 , 2025.
- Xu et al. (2023) Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang. Wizardlm: Empowering large language models to follow complex instructions. arXiv preprint arXiv:2304.12244 , 2023.
- Xu et al. (2024) Zhangchen Xu, Fengqing Jiang, Luyao Niu, Yuntian Deng, Radha Poovendran, Yejin Choi, and Bill Yuchen Lin. Magpie: Alignment data synthesis from scratch by prompting aligned LLMs with nothing. arXiv preprint arXiv:2406.08464 , 2024.
- Yang et al. (2025a) An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chang Gao, Chengen Huang, Chenxu Lv, et al. Qwen3 technical report. arXiv preprint arXiv:2505.09388 , 2025a.
- Yang et al. (2025b) John Yang, Kilian Lieret, Carlos E Jimenez, Alexander Wettig, Kabir Khandpur, Yanzhe Zhang, Binyuan Hui, Ofir Press, Ludwig Schmidt, and Diyi Yang. Swe-smith: Scaling data for software engineering agents. arXiv preprint arXiv:2504.21798 , 2025b.

## 附錄 A 附錄

表 10：按領域劃分的技能總結

### A.1 合成軌跡分析

我們計算了軌跡中令牌數量（圖 5）和輪次（圖 6）的分佈，將合成任務與資料集適配器分開。

[FIGURE:token_stats.png] 圖 5：生成軌跡中令牌數量的分佈。

[FIGURE:turn_stats.png] 圖 6：生成軌跡中輪次的分佈。

### A.2 軌跡生成的詳細資訊

我們使用 Terminus 2 為 SFT 生成所有軌跡。我們在圖 7 中提供了完整的 Terminus 2 系統提示範本，其中包括 instruction 和 terminal_state 的佔位符。我們的 Terminal-Task-Gen 管道生成具有明確指令的任務，這些指令取代 instruction 佔位符。對於資料集適配器，我們改為插入原始提示，後面跟著特定領域的後綴，如圖 8–10 所示。terminal_state 佔位符填入最新的終端輸出，以摘要當前 shell 狀態。

圖 7：Terminus 2 的系統提示範本。

圖 8：數學資料集適配器的指令範本。

圖 9：程式碼資料集適配器的指令範本。

圖 10：SWE 資料集適配器的指令範本。

### A.3 合成任務生成詳細資訊

**原始技能的策劃**

我們在表 10 中展示了各個領域的技能類型和範例。這些領域涵蓋了終端交互所需的廣泛功能。例如，安全任務涉及系統、資料處理、網路安全、演算法和測試等技能類型，具有實際應用（如製作利用漏洞的有效負載以繞過身份驗證）。同樣地，軟體工程結合了演算法和系統技能來實現複雜邏輯，如用於相依性解析的圖形遍歷。檔案操作和系統管理專注於核心基礎設施任務，範圍從解析結構化格式（JSON/XML/CSV）到管理檔案權限和自動化服務配置。我們還為資料科學、科學運算和資料處理策劃了專門技能，這些領域需要數學和統計專業知識來建立轉換管道或計算機率分佈之間的距離指標。透過系統地將這些原始技能從低階檔案系統操作分類到高階演算法推理，我們確保全面涵蓋自主代理必須在終端環境中應對的挑戰。

**合成任務生成提示詞**

我們採用了一種模組化提示詞策略，融合了結構骨幹與專門約束。圖 11 呈現了系統提示詞，它控制一般任務邏輯，而圖 12–19 則詳細說明了注入到此模板中的領域特定需求模組。這些模組為各個垂直領域定義了前置條件和目標；例如，安全模組要求製作利用漏洞的有效負載以識別脆弱性，而資料處理模組則需要使用插值來建立轉換管道。這確保了生成的任務與先前概述的多樣化原始技能完全一致。

圖 11：用於所有技能型生成的提示詞模板。領域特定模組被插入第 2 部分。

圖 12：資料處理任務的模組。

圖 13：資料查詢任務的模組。

圖 14：資料科學任務的模組。

圖 15：除錯任務的模組。

圖 16：檔案操作任務的模組。

圖 17：科學運算任務的模組。

圖 18：安全任務的模組。

圖 19：軟體工程任務的模組。

圖 20：系統管理任務的模組。