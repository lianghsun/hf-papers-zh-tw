# 論文摘要翻譯

離散影像 tokenizer 已成為現代視覺和多模態系統的關鍵元件，為基於 transformer 的架構提供了序列化介面。然而，大多數現有方法主要仍優化於重建和壓縮，通常產生捕捉局部紋理而非物體級語義結構的 token。受人類溝通的增量和組成特性啟發，我們引入 COMmunication 啟發的 Tokenization（COMiT），一個用於學習結構化離散視覺 token 序列的框架。COMiT 通過迭代觀察局部影像裁剪和循環更新其離散表示，在固定 token 預算內構造潛在訊息。在每一步，模型整合新的視覺資訊，同時精煉和重新組織現有的 token 序列。經過數個編碼迭代後，最終訊息條件化一個 flow-matching 解碼器來重建完整影像。編碼和解碼都在單一 transformer 模型內實現，並使用 flow-matching 重建和語義表示對齐損失組合的端到端訓練。我們的實驗證明，雖然語義對齐提供了基礎，但專注的序列 tokenization 對於引發可解釋的物體中心 token 結構，以及顯著改善相比先前方法的組合泛化和關係推理至關重要。