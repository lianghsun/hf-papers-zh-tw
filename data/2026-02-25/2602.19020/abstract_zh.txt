# 論文摘要翻譯

檢測大語言模型（LLM）訓練資料通常被框架化為成員推斷攻擊（MIA）問題。然而，傳統的 MIA 被動地對固定的模型權重進行操作，使用對數概率或文本生成。在本研究中，我們引入主動資料重建攻擊（ADRA），一類透過訓練主動誘導模型重建給定文本的 MIA 方法。我們假設訓練資料的可重建性優於非成員資料，並且可以利用它們的可重建性差異進行成員推斷。基於強化學習（RL）能夠強化權重中已編碼行為的發現，我們利用策略上的 RL 來主動引發資料重建，方法是從目標模型初始化一個策略進行微調。為了有效地將 RL 用於 MIA，我們設計了重建指標和對比獎勵。所得的演算法 ADRA 及其自適應變體 ADRA+，在候選資料池中改進了重建和檢測性能。實驗顯示，我們的方法在檢測預訓練、後訓練和蒸餾資料方面始終優於現有 MIA，相比之前最佳方法平均改進 10.7%。特別地，ADRA+ 在 BookMIA 預訓練檢測上相比 Min-K%++ 改進 18.8%，在 AIME 後訓練檢測上改進 7.6%。