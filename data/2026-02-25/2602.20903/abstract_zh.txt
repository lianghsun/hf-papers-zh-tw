# 視覺文字渲染的結構異常感知強化學習策略

視覺文字渲染（VTR）在文字轉圖像生成中仍然是一項關鍵挑戰，即使是先進的模型也經常產生具有結構異常的文字，例如扭曲、模糊和不對齊。然而，我們發現領先的 MLLM 和專業 OCR 模型在很大程度上無法感知這些結構異常，為 VTR 評估和基於強化學習的優化都造成了關鍵瓶頸。因此，即使是最先進的生成器（例如 SeedDream4.0、Qwen-Image）仍然難以渲染結構忠實的文字。為了解決這個問題，我們提出了 TextPecker，一種即插即用的結構異常感知強化學習策略，可以減輕嘈雜的獎勵信號並與任何文字轉圖像生成器相配合。為了實現這一能力，我們構建了具有字符級結構異常標註的識別數據集，並開發了筆劃編輯合成引擎以擴展結構錯誤覆蓋範圍。實驗表明 TextPecker 持續改進多種文字轉圖像模型；即使在經過充分優化的 Qwen-Image 上，它也能為中文文字渲染顯著提升平均 4% 的結構保真度和 8.7% 的語義對齊，確立了高保真 VTR 的新技術水平。本工作填補了 VTR 優化的空白，為實現可靠且結構忠實的視覺文字生成提供了基礎性步驟。