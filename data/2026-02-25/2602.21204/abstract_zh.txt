# 論文摘要翻譯

測試時訓練（Test-time training, TTT）搭配 KV binding 作為序列建模層，通常被解釋為一種線上後設學習（online meta-learning），在測試時記憶化鍵值對應。然而，我們的分析揭示了多個現象與這種基於記憶化的解釋相悖。基於這些發現，我們重新審視 TTT 的公式化，證明一大類 TTT 架構可以表示為學習線性注意力算子（learned linear attention operator）的形式。除了解釋先前令人困惑的模型行為外，這個視角還帶來多項實際的好處：它使原理性的架構簡化成為可能，允許完全並行的公式化同時保持效能並改進效率，並提供將多種 TTT 變體系統化地化約為標準線性注意力形式的方法。總體而言，我們的研究結果將 TTT 重新定義不是測試時記憶化，而是具有增強表示能力的學習線性注意力。