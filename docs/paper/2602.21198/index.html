<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>å¾è©¦éŒ¯ä¸­å­¸ç¿’ï¼šå…·èº« LLM çš„åæ€æ€§æ¸¬è©¦æ™‚é–“è¦åŠƒ â€” HF Papers ç¹ä¸­</title>
  <link rel="stylesheet" href="../../assets/style.css">
  
</head>
<body>
  <header class="site-header">
    <div class="container">
      <a href="../../index.html" class="site-logo">ğŸ“„ HF Papers ç¹ä¸­</a>
      <nav>
        <a href="../../index.html">é¦–é </a>
        <a href="https://huggingface.co/papers" target="_blank" rel="noopener">HuggingFace</a>
      </nav>
    </div>
  </header>

  <main class="container">
    

<div class="paper-page-header">
  <a href="../../2026-02-25/index.html" style="font-size:0.85rem; color:var(--text-muted);">
    â† 2026-02-25 è«–æ–‡åˆ—è¡¨
  </a>
  <h1 style="margin-top:0.75rem;">å¾è©¦éŒ¯ä¸­å­¸ç¿’ï¼šå…·èº« LLM çš„åæ€æ€§æ¸¬è©¦æ™‚é–“è¦åŠƒ</h1>
  
  <div class="en-title">Learning from Trials and Errors: Reflective Test-Time Planning for Embodied LLMs</div>
  

  <div class="paper-meta">
    
    <span>Yining Hong, Huang Huang, Manling Li, Li Fei-Fei, Jiajun Wu, Yejin Choi</span>
    
    <span>arXiv: <a href="https://arxiv.org/abs/2602.21198" target="_blank">2602.21198</a></span>
  </div>

  <div class="paper-links">
    <a href="https://arxiv.org/pdf/2602.21198" target="_blank" rel="noopener" class="btn btn-primary">PDF åŸæ–‡</a>
    <a href="https://arxiv.org/abs/2602.21198" target="_blank" rel="noopener" class="btn btn-outline">arXiv é é¢</a>
    <a href="https://huggingface.co/papers/2602.21198" target="_blank" rel="noopener" class="btn btn-outline">HF é é¢</a>
  </div>

  <div class="tags">
    <span class="tag domain">RL</span><span class="tag domain">Robotics</span><span class="tag domain">Multimodal</span>
    <span class="tag method">Test-Time Planning</span><span class="tag method">Test-Time Training</span><span class="tag method">LLM</span><span class="tag method">Reflection</span>
    <span class="tag task">Task Planning</span><span class="tag task">Robot Control</span><span class="tag task">Long-Horizon Decision Making</span>
    
  </div>
</div>

<!-- Abstract -->
<div class="abstract-box">
  <h2>æ‘˜è¦</h2>
  <p># è«–æ–‡æ‘˜è¦ç¿»è­¯

å…·èº« LLM ç‚ºæ©Ÿå™¨äººè³¦äºˆé«˜éšä»»å‹™æ¨ç†èƒ½åŠ›ï¼Œä½†å®ƒå€‘ç„¡æ³•åæ€å‡ºç¾äº†ä»€éº¼å•é¡Œæˆ–åŸå› ç‚ºä½•ï¼Œå°è‡´éƒ¨ç½²è®Šæˆä¸€é€£ä¸²ç¨ç«‹è©¦é©—ï¼ŒéŒ¯èª¤é‡è¤‡ç™¼ç”Ÿè€Œéç´¯ç©æˆç¶“é©—ã€‚åŸºæ–¼äººé¡åæ€å‹å¯¦è¸è€…çš„æ¦‚å¿µï¼Œæˆ‘å€‘å¼•å…¥åæ€æ€§æ¸¬è©¦æ™‚è¦åŠƒï¼ˆReflective Test-Time Planningï¼‰ï¼Œæ•´åˆå…©ç¨®åæ€æ¨¡å¼ï¼šè¡Œå‹•ä¸­åæ€ï¼ˆreflection-in-actionï¼‰ï¼Œå…¶ä¸­ä»£ç†ä½¿ç”¨æ¸¬è©¦æ™‚ç¸®æ”¾åœ¨åŸ·è¡Œå‰é€éå…§éƒ¨åæ€ç”Ÿæˆä¸¦è©•ä¼°å¤šå€‹å€™é¸å‹•ä½œï¼›ä»¥åŠè¡Œå‹•å¾Œåæ€ï¼ˆreflection-on-actionï¼‰ï¼Œåˆ©ç”¨æ¸¬è©¦æ™‚è¨“ç·´åœ¨åŸ·è¡Œå¾ŒåŸºæ–¼å¤–éƒ¨åæ€æ›´æ–°å…¶å…§éƒ¨åæ€æ¨¡å‹å’Œå‹•ä½œç­–ç•¥ã€‚æˆ‘å€‘ä¹ŸåŒ…å«å›æº¯æ€§åæ€ï¼Œä½¿ä»£ç†èƒ½é‡æ–°è©•ä¼°è¼ƒæ—©çš„æ±ºç­–ï¼Œä¸¦é€éäº‹å¾ŒçŸ¥è­˜é€²è¡Œæ¨¡å‹æ›´æ–°ï¼Œä»¥é”æˆé©ç•¶çš„é•·è¦–é‡ä¿¡ç”¨åˆ†é…ã€‚åœ¨æˆ‘å€‘æ–°è¨­è¨ˆçš„é•·è¦–é‡å®¶å‹™åŸºæº–å’Œ MuJoCo æ«¥æ«ƒçµ„è£åŸºæº–ä¸Šçš„å¯¦é©—é¡¯ç¤ºç›¸æ¯”æ–¼åŸºç·šæ¨¡å‹æœ‰é¡¯è‘—æ”¹é€²ï¼Œæ¶ˆèç ”ç©¶é©—è­‰äº†è¡Œå‹•ä¸­åæ€å’Œè¡Œå‹•å¾Œåæ€çš„äº’è£œè§’è‰²ã€‚å®šæ€§åˆ†æåŒ…æ‹¬å¯¦é«”æ©Ÿå™¨äººè©¦é©—ï¼Œå¼·èª¿äº†é€éåæ€é€²è¡Œçš„è¡Œç‚ºä¿®æ­£ã€‚</p>
  
  <div class="abstract-en">Embodied LLMs endow robots with high-level task reasoning, but they cannot reflect on what went wrong or why, turning deployment into a sequence of independent trials where mistakes repeat rather than accumulate into experience. Drawing upon human reflective practitioners, we introduce Reflective Test-Time Planning, which integrates two modes of reflection: reflection-in-action, where the agent uses test-time scaling to generate and score multiple candidate actions using internal reflections before execution; and reflection-on-action, which uses test-time training to update both its internal reflection model and its action policy based on external reflections after execution. We also include retrospective reflection, allowing the agent to re-evaluate earlier decisions and perform model updates with hindsight for proper long-horizon credit assignment. Experiments on our newly-designed Long-Horizon Household benchmark and MuJoCo Cupboard Fitting benchmark show significant gains over baseline models, with ablative studies validating the complementary roles of reflection-in-action and reflection-on-action. Qualitative analyses, including real-robot trials, highlight behavioral correction through reflection.</div>
  
</div>

<!-- Full paper content -->
<div class="paper-body">
  
</div>

  </main>

  <footer class="site-footer">
    <div class="container">
      <p>æ¯æ—¥è‡ªå‹•æŠ“å– <a href="https://huggingface.co/papers" target="_blank">HuggingFace Daily Papers</a>ï¼Œä»¥ Claude AI ç¿»è­¯ç‚ºç¹é«”ä¸­æ–‡ã€‚</p>
    </div>
  </footer>
</body>
</html>