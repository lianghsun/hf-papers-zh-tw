<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>ç™¼ç¾ä¸¦ä¿®æ­£ç¼ºé™·ï¼šé€šéæ™ºèƒ½é«”æ•¸æ“šåˆæˆä½¿ VLMs å’Œ Diffusion Models ç†è§£è¦–è¦ºå½å½± â€” HF Papers ç¹ä¸­</title>
  <link rel="stylesheet" href="../../assets/style.css">
  
</head>
<body>
  <header class="site-header">
    <div class="container">
      <a href="../../index.html" class="site-logo">ğŸ“„ HF Papers ç¹ä¸­</a>
      <nav>
        <a href="../../index.html">é¦–é </a>
        <a href="https://huggingface.co/papers" target="_blank" rel="noopener">HuggingFace</a>
      </nav>
    </div>
  </header>

  <main class="container">
    

<div class="paper-page-header">
  <a href="../../2026-02-25/index.html" style="font-size:0.85rem; color:var(--text-muted);">
    â† 2026-02-25 è«–æ–‡åˆ—è¡¨
  </a>
  <h1 style="margin-top:0.75rem;">ç™¼ç¾ä¸¦ä¿®æ­£ç¼ºé™·ï¼šé€šéæ™ºèƒ½é«”æ•¸æ“šåˆæˆä½¿ VLMs å’Œ Diffusion Models ç†è§£è¦–è¦ºå½å½±</h1>
  
  <div class="en-title">See and Fix the Flaws: Enabling VLMs and Diffusion Models to Comprehend Visual Artifacts via Agentic Data Synthesis</div>
  

  <div class="paper-meta">
    
    <span>Jaehyun Park, Minyoung Ahn, Minkyu Kim, Jonghyun Lee, Jae-Gil Lee, Dongmin Park</span>
    
    <span>arXiv: <a href="https://arxiv.org/abs/2602.20951" target="_blank">2602.20951</a></span>
  </div>

  <div class="paper-links">
    <a href="https://arxiv.org/pdf/2602.20951" target="_blank" rel="noopener" class="btn btn-primary">PDF åŸæ–‡</a>
    <a href="https://arxiv.org/abs/2602.20951" target="_blank" rel="noopener" class="btn btn-outline">arXiv é é¢</a>
    <a href="https://huggingface.co/papers/2602.20951" target="_blank" rel="noopener" class="btn btn-outline">HF é é¢</a>
  </div>

  <div class="tags">
    <span class="tag domain">CV</span><span class="tag domain">Multimodal</span>
    <span class="tag method">Diffusion Models</span><span class="tag method">Transformer</span><span class="tag method">Agent-based Synthesis</span>
    <span class="tag task">Image Generation</span><span class="tag task">Artifact Detection</span><span class="tag task">Image Quality Enhancement</span>
    <span class="tag open">Open Source</span>
  </div>
</div>

<!-- Abstract -->
<div class="abstract-box">
  <h2>æ‘˜è¦</h2>
  <p># è«–æ–‡æ‘˜è¦ç¿»è­¯

å„˜ç®¡æ“´æ•£æ¨¡å‹æœ€è¿‘å–å¾—äº†é€²å±•ï¼ŒAI ç”Ÿæˆçš„åœ–åƒä»ç„¶å¸¸å¸¸åŒ…å«æå®³çœŸå¯¦æ„Ÿçš„è¦–è¦ºç‘•ç–µã€‚é›–ç„¶æ›´æ·±å…¥çš„é è¨“ç·´å’Œæ›´å¤§çš„æ¨¡å‹å¯èƒ½æœƒæ¸›å°‘ç‘•ç–µï¼Œä½†ç„¡æ³•ä¿è­‰èƒ½å®Œå…¨æ¶ˆé™¤é€™äº›ç‘•ç–µï¼Œé€™ä½¿å¾—ç‘•ç–µç·©è§£æˆç‚ºä¸€å€‹æ¥µå…¶é—œéµçš„ç ”ç©¶é ˜åŸŸã€‚ä»¥å¾€çš„ç‘•ç–µæ„ŸçŸ¥æ–¹æ³•ä¾è³´æ–¼äººå·¥æ¨™è¨»çš„ç‘•ç–µè³‡æ–™é›†ï¼Œé€™äº›è³‡æ–™é›†æˆæœ¬é«˜æ˜‚ä¸”é›£ä»¥æ“´å±•ï¼Œçªé¡¯äº†éœ€è¦ä¸€ç¨®è‡ªå‹•åŒ–æ–¹æ³•ä¾†å¯é åœ°ç²å–ç‘•ç–µè¨»è§£è³‡æ–™é›†çš„è¿«åˆ‡æ€§ã€‚æœ¬æ–‡æå‡ºäº† ArtiAgentï¼Œå®ƒèƒ½é«˜æ•ˆåœ°å‰µå»ºçœŸå¯¦åœ–åƒå’Œç‘•ç–µæ³¨å…¥åœ–åƒçš„é…å°ã€‚è©²æ–¹æ³•åŒ…å«ä¸‰å€‹æ™ºèƒ½é«”ï¼šæ„ŸçŸ¥æ™ºèƒ½é«”å¾çœŸå¯¦åœ–åƒä¸­è­˜åˆ¥å’Œå®šä½å¯¦é«”åŠå­å¯¦é«”ï¼›åˆæˆæ™ºèƒ½é«”é€éåœ¨æ“´æ•£ Transformer ä¸­é€²è¡Œæ–°ç©çš„é€å¡ŠåµŒå…¥æ“ä½œä¾†å¼•å…¥ç‘•ç–µï¼›ç­–å±•æ™ºèƒ½é«”å°åˆæˆçš„ç‘•ç–µé€²è¡Œéæ¿¾ï¼Œä¸¦ç‚ºæ¯å€‹å¯¦ä¾‹ç”Ÿæˆå±€éƒ¨å’Œå…¨å±€è§£é‡‹ã€‚ä½¿ç”¨ ArtiAgentï¼Œæˆ‘å€‘åˆæˆäº† 100K å¼µåœ–åƒï¼Œä¸¦åœ¨å¤šç¨®æ‡‰ç”¨ä¸­å±•ç¤ºäº†æœ‰æ•ˆæ€§å’Œå¤šåŠŸèƒ½æ€§ã€‚ç¨‹å¼ç¢¼å¯åœ¨æä¾›çš„é€£çµå–å¾—ã€‚</p>
  
  <div class="abstract-en">Despite recent advances in diffusion models, AI generated images still often contain visual artifacts that compromise realism. Although more thorough pre-training and bigger models might reduce artifacts, there is no assurance that they can be completely eliminated, which makes artifact mitigation a highly crucial area of study. Previous artifact-aware methodologies depend on human-labeled artifact datasets, which are costly and difficult to scale, underscoring the need for an automated approach to reliably acquire artifact-annotated datasets. In this paper, we propose ArtiAgent, which efficiently creates pairs of real and artifact-injected images. It comprises three agents: a perception agent that recognizes and grounds entities and subentities from real images, a synthesis agent that introduces artifacts via artifact injection tools through novel patch-wise embedding manipulation within a diffusion transformer, and a curation agent that filters the synthesized artifacts and generates both local and global explanations for each instance. Using ArtiAgent, we synthesize 100K images with rich artifact annotations and demonstrate both efficacy and versatility across diverse applications. Code is available at link.</div>
  
</div>

<!-- Full paper content -->
<div class="paper-body">
  
    
      <p>[51] Junyan Ye, Baichuan Zhou, Zilong Huang, Junan Zhang, Tianyi Bai, Hengrui Kang, Jun He, Honglin Lin, Zihao Wang, Tong Wu åŠå…¶ä»–äººã€‚Lokiï¼šä½¿ç”¨å¤§å‹å¤šæ¨¡æ…‹æ¨¡å‹çš„ç¶œåˆåˆæˆè³‡æ–™æª¢æ¸¬åŸºæº–ã€‚Arxiv é å°æœ¬ Arxiv:2410.09732ï¼Œ2024ã€‚3ã€6ã€15</p>
    
  
</div>

  </main>

  <footer class="site-footer">
    <div class="container">
      <p>æ¯æ—¥è‡ªå‹•æŠ“å– <a href="https://huggingface.co/papers" target="_blank">HuggingFace Daily Papers</a>ï¼Œä»¥ Claude AI ç¿»è­¯ç‚ºç¹é«”ä¸­æ–‡ã€‚</p>
    </div>
  </footer>
</body>
</html>