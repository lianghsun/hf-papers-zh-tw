<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>æŸ¥è©¢ç„¦é»å’Œè¨˜æ†¶æ„ŸçŸ¥é‡æ’å™¨ç”¨æ–¼é•·æ–‡æœ¬è™•ç† â€” HF Papers ç¹ä¸­</title>
  <link rel="stylesheet" href="../../assets/style.css">
  
</head>
<body>
  <header class="site-header">
    <div class="container">
      <a href="../../index.html" class="site-logo">ğŸ“„ HF Papers ç¹ä¸­</a>
      <nav>
        <a href="../../index.html">é¦–é </a>
        <a href="https://huggingface.co/papers" target="_blank" rel="noopener">HuggingFace</a>
      </nav>
    </div>
  </header>

  <main class="container">
    

<div class="paper-page-header">
  <a href="../../2026-02-25/index.html" style="font-size:0.85rem;color:var(--text-muted);">
    â† 2026-02-25 è«–æ–‡åˆ—è¡¨
  </a>
  <h1 style="margin-top:0.75rem;">æŸ¥è©¢ç„¦é»å’Œè¨˜æ†¶æ„ŸçŸ¥é‡æ’å™¨ç”¨æ–¼é•·æ–‡æœ¬è™•ç†</h1>
  
  <div class="en-title">Query-focused and Memory-aware Reranker for Long Context Processing</div>
  

  <div class="paper-meta">
    
    <span>Yuqing Li, Jiangnan Li, Mo Yu, Guoxuan Ding, Zheng Lin, Weiping Wang, Jie Zhou</span>
    
    <span>arXiv: <a href="https://arxiv.org/abs/2602.12192" target="_blank">2602.12192</a></span>
    
    <span style="color:var(--text-muted);font-size:0.8rem;">
      ä¾†æºï¼šPDF + DotsOCR
    </span>
    
  </div>

  <div class="paper-links">
    <a href="https://arxiv.org/pdf/2602.12192" target="_blank" rel="noopener" class="btn btn-primary">PDF åŸæ–‡</a>
    <a href="https://arxiv.org/abs/2602.12192" target="_blank" rel="noopener" class="btn btn-outline">arXiv</a>
    <a href="https://huggingface.co/papers/2602.12192" target="_blank" rel="noopener" class="btn btn-outline">HF é é¢</a>
  </div>

  <div class="tags">
    <span class="tag domain">NLP</span>
    <span class="tag method">Transformer</span><span class="tag method">Attention Mechanism</span><span class="tag method">Reranking</span>
    <span class="tag task">Information Retrieval</span><span class="tag task">Passage Ranking</span><span class="tag task">Question Answering</span>
    
  </div>
</div>

<!-- Abstract -->
<div class="abstract-box">
  <h2>æ‘˜è¦</h2>
  <p># è«–æ–‡æ‘˜è¦ç¿»è­¯

åŸºæ–¼å°å¤§å‹èªè¨€æ¨¡å‹ä¸­æª¢ç´¢é ­ï¼ˆretrieval headsï¼‰çš„ç¾æœ‰åˆ†æï¼Œæˆ‘å€‘æå‡ºäº†ä¸€å€‹æ›¿ä»£æ€§çš„é‡æ’åºæ¡†æ¶ï¼Œè©²æ¡†æ¶è¨“ç·´æ¨¡å‹ä½¿ç”¨æ‰€é¸é ­éƒ¨çš„æ³¨æ„åŠ›åˆ†æ•¸ä¾†ä¼°è¨ˆæ®µè½-æŸ¥è©¢çš„ç›¸é—œæ€§ã€‚é€™ç¨®æ–¹æ³•æä¾›äº†ä¸€å€‹åˆ—è¡¨å¼è§£æ±ºæ–¹æ¡ˆï¼Œåœ¨æ’åºéç¨‹ä¸­å……åˆ†åˆ©ç”¨æ•´å€‹å€™é¸åˆ—è¡¨ä¸­çš„æ•´é«”è³‡è¨Šã€‚åŒæ™‚ï¼Œå®ƒè‡ªç„¶åœ°ç”¢ç”Ÿé€£çºŒçš„ç›¸é—œæ€§åˆ†æ•¸ï¼Œèƒ½å¤ åœ¨ä»»æ„æª¢ç´¢è³‡æ–™é›†ä¸Šé€²è¡Œè¨“ç·´ï¼Œç„¡éœ€ä¾è³´ Likert é‡è¡¨ç›£ç£ã€‚æˆ‘å€‘çš„æ¡†æ¶è¼•é‡ä¸”æœ‰æ•ˆï¼Œåªéœ€è¦å°è¦æ¨¡æ¨¡å‹ï¼ˆä¾‹å¦‚ 4B åƒæ•¸ï¼‰å³å¯é”åˆ°å¼·å¤§çš„æ€§èƒ½ã€‚å»£æ³›çš„å¯¦é©—è¡¨æ˜ï¼Œæˆ‘å€‘çš„æ–¹æ³•åœ¨å¤šå€‹é ˜åŸŸï¼ˆåŒ…æ‹¬ç¶­åŸºç™¾ç§‘å’Œé•·æ•˜è¿°è³‡æ–™é›†ï¼‰ä¸Šå„ªæ–¼ç¾æœ‰çš„æœ€å…ˆé€²çš„é€é»å¼å’Œåˆ—è¡¨å¼é‡æ’åºå™¨ã€‚å®ƒé€²ä¸€æ­¥åœ¨ LoCoMo åŸºæº–ä¸Šå»ºç«‹äº†æ–°çš„æœ€å…ˆé€²çµæœï¼Œè©²åŸºæº–è©•ä¼°å°è©±ç†è§£å’Œè¨˜æ†¶ä½¿ç”¨çš„èƒ½åŠ›ã€‚æˆ‘å€‘é€²ä¸€æ­¥å±•ç¤ºäº†æˆ‘å€‘çš„æ¡†æ¶æ”¯æŒéˆæ´»çš„æ“´å±•ã€‚ä¾‹å¦‚ï¼Œç”¨ä¸Šä¸‹æ–‡è³‡è¨Šå¢å¼·å€™é¸æ®µè½é€²ä¸€æ­¥æé«˜äº†æ’åºæº–ç¢ºæ€§ï¼Œè€Œå¾ä¸­é–“å±¤è¨“ç·´æ³¨æ„åŠ›é ­å¢å¼·äº†æ•ˆç‡ï¼ŒåŒæ™‚ä¸çŠ§ç‰²æ€§èƒ½ã€‚</p>
  
  <div class="abstract-en">Built upon the existing analysis of retrieval heads in large language models, we propose an alternative reranking framework that trains models to estimate passage-query relevance using the attention scores of selected heads. This approach provides a listwise solution that leverages holistic information within the entire candidate shortlist during ranking. At the same time, it naturally produces continuous relevance scores, enabling training on arbitrary retrieval datasets without requiring Likert-scale supervision. Our framework is lightweight and effective, requiring only small-scale models (e.g., 4B parameters) to achieve strong performance. Extensive experiments demonstrate that our method outperforms existing state-of-the-art pointwise and listwise rerankers across multiple domains, including Wikipedia and long narrative datasets. It further establishes a new state-of-the-art on the LoCoMo benchmark that assesses the capabilities of dialogue understanding and memory usage. We further demonstrate that our framework supports flexible extensions. For example, augmenting candidate passages with contextual information further improves ranking accuracy, while training attention heads from middle layers enhances efficiency without sacrificing performance.</div>
  
</div>

<!-- Full translated content -->
<div class="paper-body">
  
    <p style="color:var(--text-muted);font-style:italic;">å…¨æ–‡ç¿»è­¯å°šæœªç”Ÿæˆã€‚</p>
  
</div>


  </main>

  <footer class="site-footer">
    <div class="container">
      <p>æ¯æ—¥è‡ªå‹•æŠ“å– <a href="https://huggingface.co/papers" target="_blank">HuggingFace Daily Papers</a>ï¼Œä»¥ Claude AI ç¿»è­¯ç‚ºç¹é«”ä¸­æ–‡ã€‚</p>
    </div>
  </footer>
</body>
</html>