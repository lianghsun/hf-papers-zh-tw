<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>veScale-FSDPï¼šéˆæ´»ä¸”é«˜æ•ˆèƒ½çš„å¤§è¦æ¨¡ FSDP â€” HF Papers ç¹ä¸­</title>
  <link rel="stylesheet" href="../../assets/style.css">
  
</head>
<body>
  <header class="site-header">
    <div class="container">
      <a href="../../index.html" class="site-logo">ğŸ“„ HF Papers ç¹ä¸­</a>
      <nav>
        <a href="../../index.html">é¦–é </a>
        <a href="https://huggingface.co/papers" target="_blank" rel="noopener">HuggingFace</a>
      </nav>
    </div>
  </header>

  <main class="container">
    

<div class="paper-page-header">
  <a href="../../2026-02-27/index.html" style="font-size:0.85rem;color:var(--text-muted);">
    â† 2026-02-27 è«–æ–‡åˆ—è¡¨
  </a>
  <h1 style="margin-top:0.75rem;">veScale-FSDPï¼šéˆæ´»ä¸”é«˜æ•ˆèƒ½çš„å¤§è¦æ¨¡ FSDP</h1>
  
  <div class="en-title">veScale-FSDP: Flexible and High-Performance FSDP at Scale</div>
  

  <div class="paper-meta">
    
    <span>Zezhou Wang, Youjie Li, Zhiqi Lin, Jiacheng Yang, Cong Xie, Guanyu Feng, Zheng Zhong, Ziyue Huang, Hongyu Zhu, Zhi Zhang, Yanghua Peng, Xin Liu</span>
    
    <span>arXiv: <a href="https://arxiv.org/abs/2602.22437" target="_blank">2602.22437</a></span>
    
    <span style="color:var(--text-muted);font-size:0.8rem;">
      ä¾†æºï¼šarxiv HTML
    </span>
    
  </div>

  <div class="paper-links">
    <a href="https://arxiv.org/pdf/2602.22437" target="_blank" rel="noopener" class="btn btn-primary">PDF åŸæ–‡</a>
    <a href="https://arxiv.org/abs/2602.22437" target="_blank" rel="noopener" class="btn btn-outline">arXiv</a>
    <a href="https://huggingface.co/papers/2602.22437" target="_blank" rel="noopener" class="btn btn-outline">HF é é¢</a>
  </div>

  <div class="tags">
    <span class="tag domain">Theory</span>
    <span class="tag method">FSDP</span><span class="tag method">ZeRO</span><span class="tag method">RaggedShard</span><span class="tag method">Distributed Training</span><span class="tag method">Quantization</span>
    <span class="tag task">Large-scale Model Training</span>
    
  </div>
</div>

<!-- Abstract -->
<div class="abstract-box">
  <h2>æ‘˜è¦</h2>
  <p># Fully Sharded Data Parallel (FSDP) è«–æ–‡æ‘˜è¦ç¿»è­¯

å®Œå…¨åˆ†ç‰‡æ•¸æ“šä¸¦è¡Œï¼ˆFully Sharded Data Parallelï¼ŒFSDPï¼‰ï¼Œä¹Ÿç¨±ç‚º ZeROï¼Œå»£æ³›ç”¨æ–¼å¤§è¦æ¨¡æ¨¡å‹è¨“ç·´ï¼Œå…·æœ‰éˆæ´»æ€§å¼·ä¸”å°æ¨¡å‹ä»£ç¢¼å…¥ä¾µæœ€å°çš„ç‰¹é»ã€‚ç„¶è€Œï¼Œç¾æœ‰çš„ FSDP ç³»çµ±åœ¨çµæ§‹æ„ŸçŸ¥è¨“ç·´æ–¹æ³•ï¼ˆä¾‹å¦‚åˆ†å¡Šé‡åŒ–è¨“ç·´ï¼‰å’Œéé€å…ƒç´ å„ªåŒ–å™¨ï¼ˆä¾‹å¦‚ Shampoo å’Œ Muonï¼Œç”¨æ–¼ Geminiã€Kimi K2 ç­‰å°–ç«¯æ¨¡å‹ï¼‰æ–¹é¢å­˜åœ¨å›°é›£ã€‚FSDP å›ºå®šçš„é€å…ƒç´ æˆ–é€åˆ—åˆ†ç‰‡æ ¼å¼èˆ‡åˆ†å¡Šçµæ§‹è¨ˆç®—ç›¸è¡çªã€‚æ­¤å¤–ï¼Œç•¶å‰çš„å¯¦ç¾åœ¨é€šè¨Šå’Œè¨˜æ†¶é«”æ•ˆç‡æ–¹é¢è¡¨ç¾ä¸è¶³ï¼Œé™åˆ¶äº†æ“´å±•è‡³æ•¸è¬å€‹ GPU çš„èƒ½åŠ›ã€‚æˆ‘å€‘æ¨å‡º veScale-FSDPï¼Œä¸€å€‹é‡æ–°è¨­è¨ˆçš„ FSDP ç³»çµ±ï¼Œå°‡éˆæ´»çš„åˆ†ç‰‡æ ¼å¼ RaggedShard èˆ‡çµæ§‹æ„ŸçŸ¥è¦åŠƒæ¼”ç®—æ³•ç›¸çµåˆï¼Œåœ¨å¤§è¦æ¨¡ä¸‹æä¾›éˆæ´»æ€§å’Œæ€§èƒ½ã€‚veScale-FSDP åŸç”Ÿæ”¯æŒ FSDP æ‰€éœ€çš„é«˜æ•ˆæ•¸æ“šæ”¾ç½®ï¼Œè³¦èƒ½åˆ†å¡Šé‡åŒ–å’Œéé€å…ƒç´ å„ªåŒ–å™¨ã€‚å› æ­¤ï¼ŒveScale-FSDP ç›¸æ¯”ç¾æœ‰ FSDP ç³»çµ±å¯¦ç¾äº† 5~66% çš„ååé‡æå‡å’Œ 16~30% çš„è¨˜æ†¶é«”ä½¿ç”¨é™ä½ï¼ŒåŒæ™‚èƒ½å¤ é«˜æ•ˆåœ°æ“´å±•è‡³æ•¸è¬å€‹ GPUã€‚</p>
  
  <div class="abstract-en">Fully Sharded Data Parallel (FSDP), also known as ZeRO, is widely used for training large-scale models, featuring its flexibility and minimal intrusion on model code. However, current FSDP systems struggle with structure-aware training methods (e.g., block-wise quantized training) and with non-element-wise optimizers (e.g., Shampoo and Muon) used in cutting-edge models (e.g., Gemini, Kimi K2). FSDP&#39;s fixed element- or row-wise sharding formats conflict with the block-structured computations. In addition, today&#39;s implementations fall short in communication and memory efficiency, limiting scaling to tens of thousands of GPUs. We introduce veScale-FSDP, a redesigned FSDP system that couples a flexible sharding format, RaggedShard, with a structure-aware planning algorithm to deliver both flexibility and performance at scale. veScale-FSDP natively supports efficient data placement required by FSDP, empowering block-wise quantization and non-element-wise optimizers. As a result, veScale-FSDP achieves 5~66% higher throughput and 16~30% lower memory usage than existing FSDP systems, while scaling efficiently to tens of thousands of GPUs.</div>
  
</div>

<!-- Full translated content -->
<div class="paper-body">
  
    <p>[*]å¹³ç­‰è²¢ç» \contribution [â€ ]é€šè¨Šä½œè€…</p>
<h1 id="vescale-fsdp-fsdp">veScale-FSDPï¼šéˆæ´»ä¸”é«˜æ•ˆèƒ½çš„å¤§è¦æ¨¡ FSDP</h1>
<p>å®Œå…¨åˆ†ç‰‡è³‡æ–™ä¸¦è¡Œï¼ˆFully Sharded Data Parallel, FSDPï¼‰ï¼Œåˆç¨±ç‚º ZeROï¼Œå»£æ³›ç”¨æ–¼è¨“ç·´å¤§è¦æ¨¡æ¨¡å‹ï¼Œå…·æœ‰éˆæ´»æ€§å’Œå°æ¨¡å‹ç¨‹å¼ç¢¼çš„æœ€å°å¹²æ“¾ç­‰ç‰¹é»ã€‚ç„¶è€Œï¼Œç¾æœ‰çš„ FSDP ç³»çµ±åœ¨çµæ§‹æ„ŸçŸ¥è¨“ç·´æ–¹æ³•ï¼ˆä¾‹å¦‚åˆ†å¡Šé‡åŒ–è¨“ç·´ï¼‰å’Œæœ€å…ˆé€²æ¨¡å‹ï¼ˆä¾‹å¦‚ Geminiã€Kimi K2ï¼‰ä¸­ä½¿ç”¨çš„éå…ƒç´ ç´šå„ªåŒ–å™¨ï¼ˆä¾‹å¦‚ Shampoo å’Œ Muonï¼‰ä¸Šå­˜åœ¨å›°é›£ã€‚FSDP çš„å›ºå®šå…ƒç´ ç´šæˆ–è¡Œç´šåˆ†ç‰‡æ ¼å¼èˆ‡åˆ†å¡Šçµæ§‹è¨ˆç®—ç›¸è¡çªã€‚æ­¤å¤–ï¼Œç•¶å‰çš„å¯¦ä½œåœ¨é€šè¨Šå’Œè¨˜æ†¶é«”æ•ˆç‡ä¸Šè¡¨ç¾ä¸è¶³ï¼Œé™åˆ¶äº†æ“´å±•åˆ°æ•¸è¬å€‹ GPU çš„èƒ½åŠ›ã€‚æˆ‘å€‘å¼•å…¥ veScale-FSDPï¼Œä¸€å€‹ç¶“éé‡æ–°è¨­è¨ˆçš„ FSDP ç³»çµ±ï¼Œçµåˆéˆæ´»çš„åˆ†ç‰‡æ ¼å¼ RaggedShard å’Œçµæ§‹æ„ŸçŸ¥çš„è¦åŠƒæ¼”ç®—æ³•ï¼Œä»¥åœ¨å¤§è¦æ¨¡ä¸ŠåŒæ™‚æä¾›éˆæ´»æ€§å’Œæ•ˆèƒ½ã€‚veScale-FSDP åŸç”Ÿæ”¯æŒ FSDP æ‰€éœ€çš„é«˜æ•ˆè³‡æ–™é…ç½®ï¼Œä½¿åˆ†å¡Šé‡åŒ–å’Œéå…ƒç´ ç´šå„ªåŒ–å™¨èƒ½å¤ é‹ä½œã€‚å› æ­¤ï¼ŒveScale-FSDP ç›¸æ¯”ç¾æœ‰ FSDP ç³»çµ±é”åˆ° 5 ï½ 66% çš„ååé‡æå‡å’Œ 16 ï½ 30% çš„è¨˜æ†¶é«”ä½¿ç”¨é‡æ¸›å°‘ï¼ŒåŒæ™‚èƒ½æœ‰æ•ˆæ“´å±•åˆ°æ•¸è¬å€‹ GPUã€‚</p>
<p>and \projectpage https://github.com/volcengine/veScale</p>
<h2 id="1">1 ç°¡ä»‹</h2>
<p>å¤§å‹èªè¨€æ¨¡å‹ï¼ˆLLMsï¼‰å·²æˆç‚ºæ—¥å¸¸æ‡‰ç”¨ä¸­çš„è®Šé©æ€§æŠ€è¡“ã€‚åœ¨ç¼©æ”¾å¾‹çš„é©…å‹•ä¸‹ [ kaplan2020scaling ]ï¼ŒLLMs ç¾å·²é”åˆ°æ•¸åå„„å€‹åƒæ•¸è¦æ¨¡ï¼Œä¸¦é”åˆ°äººé¡ç´šåˆ¥çš„æ€§èƒ½ã€‚è¨“ç·´å¦‚æ­¤é¾å¤§çš„æ¨¡å‹éœ€è¦ä¸¦è¡ŒåŒ–æŠ€è¡“ï¼Œå°‡æ¨¡å‹å’Œæœ€ä½³åŒ–å™¨ç‹€æ…‹åˆ†æ•£åˆ°æ•¸åƒå€‹ GPU ä¸Š [ jiang2024megascale ]ã€‚å…¶ä¸­ï¼ŒDeepspeed ZeRO [ rajbhandari2020zero ] æˆ–å®Œå…¨åˆ†ç‰‡è³‡æ–™ä¸¦è¡Œï¼ˆFully Sharded Data Parallel, FSDPï¼‰[ zhao2023pytorch , pytorch2024fsdp2 , megatron_fsdp ] æ˜¯æœ€åŸºç¤çš„æŠ€è¡“ä¹‹ä¸€ã€‚FSDP é€šå¸¸æ˜¯é¦–é¸ï¼Œå› ç‚ºå…¶å…·æœ‰é«˜æ•ˆè€Œéˆæ´»çš„è³‡æ–™ä¸¦è¡Œç¨‹å¼è¨­è¨ˆç¯„ä¾‹ï¼Œä¸¦ä¸”èˆ‡æ¨¡å‹æ¶æ§‹è§£è€¦ã€‚ç•¶éœ€è¦é¡å¤–çš„ç¸®æ”¾æ™‚ [ smith2022using , ma2025veomni ]ï¼ŒFSDP å¯ä»¥èˆ‡å…¶ä»–ä¸¦è¡ŒåŒ–æ–¹æ³•çµåˆã€‚</p>
<p>ç„¶è€Œï¼Œç¾æœ‰çš„ FSDP/ZeRO ç³»çµ±åœ¨ç¾ä»£çµæ§‹æ„ŸçŸ¥è¨“ç·´æ–¹é¢å­˜åœ¨å›°é›£ã€‚æœ€å…ˆé€²çš„æ¨¡å‹ä½¿ç”¨éå…ƒç´ å±¤ç´šæœ€ä½³åŒ–å™¨ï¼Œå¦‚ Shampoo [ gupta2018shampoo ] å’Œ Muon [ jordan2024muon ]ï¼Œä»¥åŠåˆ†å¡Šé‡åŒ–è¨“ç·´å¦‚ DeepSeek-V3 [ liu2024deepseek ]ï¼Œé€™äº›éƒ½éœ€è¦åŸå­å¼µé‡å¡Šã€‚æ ¸å¿ƒé™åˆ¶åœ¨æ–¼ï¼Œç¾æœ‰ FSDP æ¡†æ¶è¦éº¼æŒ‰å…ƒç´ å±¤ç´š [ rajbhandari2020zero , zhao2023pytorch ]ï¼Œè¦éº¼æŒ‰è¡Œå±¤ç´š [ pytorch2024fsdp2 , megatron_fsdp ] å°åƒæ•¸ã€æ¢¯åº¦å’Œæœ€ä½³åŒ–å™¨ç‹€æ…‹é€²è¡Œåˆ†ç‰‡ï¼Œç”¢ç”Ÿçš„åˆ†ç‰‡é‚Šç•Œå¾€å¾€èˆ‡æ‰€éœ€çš„å¡Šå¤§å°ä¸å°é½ã€‚å› æ­¤ï¼Œæ¨¡å‹é–‹ç™¼äººå“¡å¿…é ˆä¾µå…¥å¼åœ°ä¿®æ”¹å…¶æ¨¡å‹æˆ–æœ€ä½³åŒ–å™¨ä»¥åŒ¹é…å¼µé‡é‚Šç•Œï¼Œæˆ–ç³»çµ±é–‹ç™¼äººå“¡å¿…é ˆè™•ç†è¤‡é›œçš„é‚Šç•Œæª¢æŸ¥ã€å¡«å……å’Œé¡å¤–çš„é€šè¨Šé‚è¼¯ã€‚</p>
<p>é™¤äº†ç¼ºä¹éˆæ´»æ€§å¤–ï¼Œç•¶å‰çš„ FSDP ç³»çµ±é‚„ç„¡æ³•é”åˆ°æˆ‘å€‘çš„ç”Ÿç”¢è¼¸é€é‡å’Œè¨˜æ†¶é«”ç›®æ¨™ï¼Œæˆ‘å€‘çš„ç›®æ¨™æ˜¯å¾ç¡¬é«”æ•ˆç‡ä¸­ç²å–æ¯ä¸€åˆ†æ•ˆèƒ½ã€‚GPU è¨˜æ†¶é«”æ˜¯æ›´ç·Šå¼µçš„ç´„æŸï¼šåœ¨å…±äº«é›†ç¾¤ä¸­ï¼Œå·¥ä½œæœƒå› è¨˜æ†¶é«”ä¸è¶³è€ŒåŸ·è¡Œï¼Œæˆ–åœ¨è¨˜æ†¶é«”é™åˆ¶ä¸‹åŸ·è¡Œï¼Œå°è‡´æ˜‚è²´çš„è¨­å‚™ç«¯ç©ºé–’ï¼Œä¿ƒä½¿éåº¦ä½ˆå»ºæµªè²» GPU è³‡æºã€‚ç•¶å°‡è¨“ç·´ç¸®æ”¾åˆ°è¶…é 10,000 å€‹ GPU å’Œæ•¸å…†åƒæ•¸æ™‚ï¼Œé€™äº›éœ€æ±‚è®Šå¾—æ›´åŠ é—œéµã€‚å¹¾ä¹æ²’æœ‰ç¾æœ‰çš„ FSDP ç³»çµ±èƒ½åœ¨ç¶­æŒæ•ˆç‡çš„åŒæ™‚ç¸®æ”¾åˆ°é€™å€‹è¦æ¨¡ã€‚Deepspeed ZeRO [ rajbhandari2020zero ] é–‹å‰µäº† FSDP ç ”ç©¶ï¼Œä½†å—åˆ°åˆ†æ•£åŒ– AllGather æ“ä½œ [ deepspeed_AG ] å’Œä½æ•ˆè¨˜æ†¶é«”ç®¡ç† [ fsdp_record_stream ] çš„å›°æ“¾ã€‚PyTorch FSDP1 [ zhao2023pytorch ] è§£æ±ºäº†ä¸€äº› AllGather ä½æ•ˆç‡å•é¡Œï¼Œä½†å°è‡´ ReduceScatter ç·©æ…¢ [ fsdp1_reduce ] ä¸”æœªè§£æ±ºè¨˜æ†¶é«”é–‹éŠ· [ fsdp_record_stream ]ã€‚PyTorch FSDP2 [ pytorch2024fsdp2 ] æ”¹é€²äº†è¨˜æ†¶é«”ç®¡ç† [ per_parameter_shard_rfc ]ï¼Œä½†å¼•å…¥äº†é«˜å¼µé‡è¤‡è£½é–‹éŠ·ã€‚åŒæ™‚ï¼ŒFSDP1 å’Œ FSDP2 éƒ½å› é€šè¨Šç·©è¡å€ä¸å°é½è€Œå°è‡´é›†é«”é€šè¨Šç·©æ…¢ [ wu2025terabyte , nccl16byte ]ã€‚Megatron-FSDP [ megatron_fsdp ] é€²ä¸€æ­¥æ”¹é€²äº†æ€§èƒ½ï¼Œä½†éœ€è¦é¡å¤–å¡«å……ï¼Œå¢åŠ äº†é€šè¨Šå’Œè¨˜æ†¶é«”æˆæœ¬ã€‚</p>
<p>ç‚ºæ­¤ï¼Œæˆ‘å€‘é‡æ–°è¨­è¨ˆäº† PyTorch FSDP2ï¼Œä¸¦æ¨å‡º veScale-FSDPï¼Œåœ¨ç¸®æ”¾æ™‚å…¼å…·éˆæ´»æ€§å’Œæ€§èƒ½ï¼š</p>
<p>âŠ³ \triangleright åœ¨éˆæ´»æ€§æ–¹é¢ï¼ŒveScale-FSDP å¼•å…¥äº†ä¸€ç¨®æ–°ç©çš„åˆ†ç‰‡æ ¼å¼ RaggedShardï¼Œæ”¯æŒå…·æœ‰è‡ªè¨‚å¡Šå¤§å°çš„ä»»æ„åˆ†ç‰‡ç²’åº¦ç”¨æ–¼çµæ§‹æ„ŸçŸ¥è¨“ç·´ï¼ŒåŒæ™‚ç„¡ç¸«çµ„åˆç¾æœ‰çš„ PyTorch DTensor åˆ†ç‰‡æ ¼å¼ã€‚</p>
<p>âŠ³ \triangleright åœ¨æ€§èƒ½æ–¹é¢ï¼ŒveScale-FSDP å¼•å…¥äº†ä¸€ç¨®è¦åŠƒæ¼”ç®—æ³•ï¼Œé‡æ–°æ’åˆ— RaggedShard å¼µé‡ä»¥æœ€å¤§åŒ–é€šè¨Šæ•ˆç‡ï¼ŒåŒæ™‚å°Šé‡å…¶æ‰€éœ€çš„åˆ†ç‰‡ç²’åº¦ã€‚æˆ‘å€‘å°‡è¦åŠƒè¡¨è¿°ç‚º NP å›°é›£æœ€ä½³åŒ–å•é¡Œï¼Œä¸¦ä½¿ç”¨å¯¦ç”¨çš„å¤šé …å¼æ™‚é–“å•Ÿç™¼å¼æ¼”ç®—æ³•ï¼Œåœ¨å¯¦è¸ä¸­é”åˆ°é«˜å“è³ªè§£æ±ºæ–¹æ¡ˆã€‚</p>
<p>âŠ³ \triangleright veScale-FSDP é€²ä¸€æ­¥æä¾›äº†ä¸€å€‹é«˜æ€§èƒ½åŸèª Distributed Bufferï¼ˆDBufferï¼‰ï¼Œä½¿ç”¨å…¨å±€ç·©è¡å€çš„åˆ‡ç‰‡æ”¯æŒ RaggedShard å¼µé‡ï¼Œä¸åƒ…å¯¦ç¾é›¶è¤‡è£½å­˜å–å’Œæœ€å°é€šè¨Šé–‹éŠ·ï¼Œé‚„é€šéæ‰¹é‡è¨˜æ†¶é«”é…ç½®æ¸›å°‘è¨˜æ†¶é«”ç¢ç‰‡åŒ–ã€‚</p>
<p>æˆ‘å€‘çš„å»£æ³›è©•ä¼°è¡¨æ˜ï¼ŒveScale-FSDP åœ¨ä¸åŒè¦æ¨¡çš„å¯†é›†å’Œç¨€ç– LLM ä¸Šéƒ½å„ªæ–¼æ‰€æœ‰ç¾æœ‰çš„ FSDP ç³»çµ±ï¼Œå¯¦ç¾äº† 5 âˆ¼ \sim 66% æ›´é«˜çš„è¼¸é€é‡å’Œ 16 âˆ¼ \sim 30% æ›´ä½çš„è¨˜æ†¶é«”ä½¿ç”¨ï¼ŒåŒæ™‚èƒ½å¤ æœ‰æ•ˆåœ°ç¸®æ”¾åˆ°æ•¸è¬å€‹ GPUã€‚æ­¤å¤–ï¼Œæ¡ˆä¾‹ç ”ç©¶è¡¨æ˜ veScale-FSDP èƒ½å¤ æœ¬åœ°æ”¯æŒéå…ƒç´ å±¤ç´šæœ€ä½³åŒ–å™¨ï¼ˆå¦‚ Muon [ jordan2024muon ]ï¼‰å’Œåˆ†å¡Šé‡åŒ–æ–¹æ³•ï¼ˆå¦‚ 8-bit Adam [ dettmers20218 ]ï¼‰ã€‚</p>
<p>veScale-FSDP å·²åœ¨ç”Ÿç”¢ç’°å¢ƒä¸­ç¶“éå¯¦æˆ°æ¸¬è©¦ï¼Œç„¡éœ€ä¾è³´å…§éƒ¨åŸºç¤è¨­æ–½å³å¯ç§»æ¤ã€‚</p>
<p>RaggedShard ä»£ç¢¼å·²é–‹æºæ–¼ https://github.com/volcengine/veScaleã€‚</p>
<h2 id="2">2 èƒŒæ™¯èˆ‡å‹•æ©Ÿ</h2>
<h3 id="21">2.1 çµæ§‹æ„ŸçŸ¥è¨“ç·´</h3>
<p>çµæ§‹æ„ŸçŸ¥è¨“ç·´æ˜¯ Gemini [ team2024gemini ] å’Œ DeepSeek [ liu2024deepseek ] ç­‰é ‚ç´šæ¨¡å‹èƒŒå¾Œçš„æ ¸å¿ƒæŠ€è¡“ï¼Œå…¶é‡è¦æ€§æ—¥ç›Šæå‡ï¼ŒåŒ…æ‹¬ï¼š</p>
<p>çŸ©é™£å„ªåŒ–å™¨ã€‚åŸºæ–¼çŸ©é™£çš„å„ªåŒ–å™¨ï¼ˆå¦‚ Shampoo [ gupta2018shampoo ] å’Œ Muon [ jordan2024muon ]ï¼‰å¯ä»¥æä¾›æ›´å¿«çš„æ”¶æ–‚é€Ÿç‡ã€‚
è¨ˆç®—æ˜¯åœ¨å…·æœ‰åŸå§‹ 2D å½¢ç‹€çš„çŸ©é™£ä¸Šé€²è¡Œçš„ï¼Œéœ€è¦å®Œæ•´çŸ©é™£åœ¨æ¯å€‹è¨­å‚™ä¸Šæœ¬åœ°å­˜åœ¨ï¼Œç„¶å¾Œåƒ…åœ¨é¸å®šçš„è¨­å‚™ä¸Šé€²è¡Œè¨ˆç®—ã€‚</p>
<p>å€å¡Šç´šé‡åŒ–ã€‚ä½¿ç”¨é‡åŒ–æ¨¡å‹ [ liu2024deepseek ] å’Œå„ªåŒ–å™¨ç‹€æ…‹ [ dettmers20218 ] é€²è¡Œè¨“ç·´è¢«å»£æ³›ä½¿ç”¨ä»¥æé«˜ç³»çµ±æ•ˆç‡ã€‚
å€å¡Šç´šé‡åŒ–æ˜¯ä¿æŒè¨“ç·´å“è³ªå’Œæ•ˆç‡çš„ä¸»æµæŠ€è¡“ä¹‹ä¸€ï¼Œä½†éœ€è¦å°‡å¼µé‡åˆ‡åˆ†ç‚º 2D å€å¡Šä»¥è¨ˆç®—ç¸®æ”¾å› å­ã€‚
ä¸è¬¹æ…åœ°åˆ†ç‰‡åƒæ•¸æœƒå°è‡´åˆ†ç‰‡å€å¡Šè·¨è¨­å‚™åˆ†æ•£ï¼Œåœ¨æ¨¡å‹è¨­è¨ˆæˆ–ç³»çµ±é–‹ç™¼ä¸­æœƒé€ æˆé«˜è¤‡é›œæ€§ã€‚</p>
<h3 id="22-dtensor-jaggedtensor">2.2 DTensor å’Œ JaggedTensor</h3>
<p><figure class="paper-figure"><img src="../../figures/2026-02-27/2602.22437/x1.png" loading="lazy"></figure> åœ– 1ï¼šç”¨æ–¼éˆæ´»é€šè¨Šå’Œè¨ˆç®—çš„ DTensorã€‚æ­¤è™•é¡¯ç¤º DTensor åœ¨è¨­å‚™ä¸ŠåŸ·è¡Œåˆ†ç‰‡çŸ©é™£ä¹˜æ³•çš„ç¯„ä¾‹ã€‚æ¯å€‹ DTensor ä¸­çš„æ·±è‰²éƒ¨åˆ†è¡¨ç¤ºè©²è¨­å‚™ä¸Šç‰©è³ªåŒ–çš„æœ¬åœ°å¼µé‡ã€‚</p>
<p>åˆ†æ•£å¼µé‡ï¼ˆDTensorï¼‰[ torch-dtensor , li2025vescale ] æ˜¯ PyTorch çš„ä¸€å€‹å¾ˆæœ‰æ½›åŠ›çš„åŸå§‹å‹åˆ¥ï¼Œç‚ºçµæ§‹æ„ŸçŸ¥è¨“ç·´æä¾›äº†æ©Ÿæœƒã€‚
å®ƒè¡¨ç¤ºè·¨è¨­å‚™åˆ†æ•£çš„å…¨å±€å¼µé‡ï¼Œå…¶ä¸­æ¯å€‹è¨­å‚™æŒæœ‰ä¸€å€‹æœ¬åœ°åˆ†ç‰‡å¼µé‡ã€‚
DTensor æ”¯æ´ä¸‰ç¨®åˆ†ç‰‡æ ¼å¼ï¼ˆä½ç½®é…ç½®ï¼‰ï¼šæ²¿è‘—å¼µé‡ç¶­åº¦å‡å‹»åˆ†ç‰‡å…¨å±€å¼µé‡çš„ Shard(dim)ã€è¤‡è£½å…¨å±€å¼µé‡çš„ Replicate ä»¥åŠ Partialã€‚å®ƒé‚„ä½¿ä½¿ç”¨è€…èƒ½å¤ é€é redistribute åœ¨é€™äº›ä½ç½®é…ç½®ä¹‹é–“åˆ‡æ›ï¼Œä¸¦å…·æœ‰éš±å¼é›†åˆé€šè¨Šã€‚
æ­¤å¤–ï¼ŒDTensor å¯ä»¥ç›´æ¥ç”± matmul ç­‰é‹ç®—å­è¨ˆç®—ï¼Œå¦‚åœ– 1 æ‰€ç¤ºã€‚
ç„¶è€Œï¼Œä¸€å€‹æ ¹æœ¬é™åˆ¶é˜»ç¤™äº†çµæ§‹æ„ŸçŸ¥è¨“ç·´ï¼šShard æ ¼å¼ç„¡æ³•è¡¨ç¤ºé‡åŒ–æ‰€éœ€çš„å€å¡Šç´šåˆ†ç‰‡æˆ–çŸ©é™£å„ªåŒ–å™¨æ‰€éœ€çš„ä¸å‡å‹»åˆ†ç‰‡ã€‚</p>
<p>å–®è¨­å‚™ä¸Šçš„ JaggedTensor/NestTensor [ jaggedtensor , nestedtensor , raggedtensors ] æ˜¯ PyTorch/TensorFlow åŸå§‹å‹åˆ¥ï¼Œè¡¨ç¤ºå…¶æœ€å¾Œç¶­åº¦ç‚ºã€Œä¸è¦å‰‡ã€çš„å–®è¨­å‚™å¼µé‡ã€‚ä¾‹å¦‚ï¼Œä¸€å€‹ 2D å¼µé‡ï¼Œå…¶ä¸­æ¯ä¸€è¡Œå¯èƒ½å…·æœ‰ä¸åŒçš„é•·åº¦ã€‚
é›–ç„¶é€™äº›åŸå§‹å‹åˆ¥ä»ç„¶æœªèƒ½ä»¥å€å¡Šç´šç²’åº¦ä½œç‚ºåŸå­å–®ä½ä¾†è¡¨ç¤ºï¼Œä½†å®ƒå€‘ç‚º veScale-FSDP å¦‚ä½•åœ¨åˆ†æ•£è¨“ç·´è¨­å®šä¸­æ”¯æŒçµæ§‹æ„ŸçŸ¥æä¾›äº†æœ‰ç”¨çš„æç¤ºã€‚</p>
<h3 id="23-zero-fsdp">2.3 ZeRO å’Œ FSDP</h3>
<p>DeepSpeed ZeRO [ rajbhandari2020zero ] é–‹å‰µäº†é€™ä¸€é¡ FSDP ç ”ç©¶çš„å…ˆæ²³ã€‚
å…¶æ ¸å¿ƒæ¦‚å¿µæ˜¯å°‡ä¸€å±¤å¼µé‡ï¼ˆåƒæ•¸ã€æ¢¯åº¦å’Œå„ªåŒ–å™¨ç‹€æ…‹ï¼‰ä¸²æ¥åœ¨ä¸€èµ·ï¼Œç„¶å¾Œå°‡æ¯å€‹ä¸²æ¥çš„å¼µé‡åˆ†ç‰‡åˆ°å¤šå€‹è¨­å‚™ä¸­ï¼Œå…¶ä¸­å¼µé‡å¯ä»¥è·¨è¨­å‚™é‚Šç•Œé€²è¡Œä¸è¦å‰‡åˆ†ç‰‡ã€‚
ZeRO åªåœ¨å‰å‘å’Œåå‘å‚³æ’­å‰ä½¿ç”¨ AllGather ä¾†éåˆ†ç‰‡ä¸€å±¤ï¼Œä¸¦ä½¿ç”¨ ReduceScatter å°‡è©²å±¤æ¢¯åº¦åŒ–ç´„å›åˆ°ä¸åŒè¨­å‚™ã€‚
é€™ç¨®åˆ†ç‰‡è¨­è¨ˆé™æ–¼é€å…ƒç´ ç´”å¼µé‡ï¼Œç„¡æ³•æ”¯æŒçµæ§‹æ„ŸçŸ¥çš„è¨“ç·´ã€‚</p>
<p>FullyShardedDataParallel (FSDP1) [ zhao2023pytorch ] æ˜¯ç¬¬ä¸€å€‹ PyTorch åŸç”Ÿ ZeROï¼Œéµå¾ªç›¸åŒçš„åˆ†ç‰‡æ ¼å¼å’Œé™åˆ¶ï¼Œä½†åœ¨æ€§èƒ½ä¸Šå¾—åˆ°äº†å„ªåŒ–ã€‚</p>
<p>è¡¨ 1ï¼šåœ¨ 64 å€‹ GPU ä¸Šçš„ GPT-OSS-120B ä¸­ï¼ŒFSDP2 ä¸­äº¤éŒ¯è¤‡è£½æ™‚é–“ï¼ˆæ¯«ç§’ï¼‰èˆ‡å…¶å°æ‡‰é›†åˆæ“ä½œçš„æ¯”è¼ƒã€‚Shard(0) æ˜¯é è¨­åƒæ•¸åˆ†ç‰‡æ¨¡å¼ï¼Œç•¶ Shard(0) ç”¢ç”Ÿå¤§é‡å¡«å……æ™‚ä½¿ç”¨ Shard(1)ã€‚</p>
<p>fully_shard (FSDP2) æ˜¯ç¬¬äºŒå€‹ PyTorch åŸç”Ÿ ZeROï¼Œä»£è¡¨äº†ç¤¾å€ä¸­æœ€å…ˆé€²çš„ FSDPã€‚
å®ƒå°‡ä¸²æ¥åˆ†ç‰‡è¨­è¨ˆæ›¿æ›ç‚ºé€åƒæ•¸åˆ†ç‰‡ï¼Œå°‡æ¯å€‹å¼µé‡è¡¨ç¤ºç‚º Shard(0) DTensorã€‚é€™ç‚º FSDP åƒæ•¸åœ¨é€šä¿¡ã€è¨ˆç®—å’Œæ¨¡å‹æª¢æŸ¥é»æ–¹é¢æä¾›äº†æœ€å¤§çš„ DTensor éˆæ´»æ€§ã€‚
ç„¶è€Œï¼Œé€™ç¨®å‡å‹»åˆ†ç‰‡æ ¼å¼ä»ç„¶é æœªèƒ½å¯¦ç¾çµæ§‹æ„ŸçŸ¥çš„è¨“ç·´ã€‚
æ­¤å¤–ï¼Œé€™ç¨®é€åƒæ•¸è¨­è¨ˆå¾äº¤éŒ¯è¨˜æ†¶é«”åœ°å€ä¸­è¤‡è£½åƒæ•¸å¼•å…¥äº†æ€§èƒ½é–‹éŠ·ï¼Œå¦‚åœ– 2 å’Œè¡¨ 1 æ‰€ç¤ºã€‚</p>
<p><figure class="paper-figure"><img src="../../figures/2026-02-27/2602.22437/x2.png" loading="lazy"></figure> åœ– 2ï¼šFSDP2 çš„åŸºæœ¬é–‹éŠ·ã€‚ï¼ˆç¤ºæ„ AllGatherï¼›ReduceScatter æ˜¯åå‘éç¨‹ã€‚ï¼‰</p>
<p>Megatron-FSDP [ megatron_fsdp ] æ˜¯è¿½æ±‚é€Ÿåº¦çš„æœ€æ–° FSDP åŸå‹ã€‚
å®ƒæ”¾æ£„äº† FSDP2 çš„è¨­è¨ˆï¼Œå›åˆ° FSDP1 çš„ä¸²æ¥åˆ†ç‰‡ä»¥é¿å…è¤‡è£½é–‹éŠ·ï¼ŒåŒæ™‚é€²è¡Œäº†å¤§é‡çš„æ€§èƒ½å„ªåŒ–ã€‚
ç„¶è€Œï¼ŒMegatron-FSDP é–‹ç™¼äº†ä¸€ç¨®ç‰¹æ®Šæ©Ÿåˆ¶ï¼Œä»¥å¼·åˆ¶ä¸€å€‹ä¸²æ¥åˆ†ç‰‡çš„å¼µé‡æˆç‚º Shard(0) DTensorï¼Œä½¿å¾—æ¨¡å‹æª¢æŸ¥é»å¯ä»¥ä½¿ç”¨ DTensorã€‚é€™å€‹æ©Ÿåˆ¶å°‡å¡«å……æ’å…¥åˆ°ä¸²æ¥ä¸­ï¼Œä»¥ä¾¿å¼µé‡æ²¿è‘—è¨­å‚™é‚Šç•Œé€²è¡Œé€åˆ—åˆ†ç‰‡ï¼Œè€Œéé€å…ƒç´ åˆ†ç‰‡ã€‚è‹¥æ²’æœ‰ä»”ç´°çš„å¡«å……è¦åŠƒï¼Œä¸²æ¥å¤§å°æœƒé¡¯è‘—å¢é•·ï¼Œå¢åŠ è¨˜æ†¶é«”ä½¿ç”¨å’Œé€šä¿¡é‡ã€‚æ­¤å¤–ï¼Œé€åˆ—åˆ†ç‰‡ä»ç„¶ä¸è¶³ä»¥æ”¯æŒçµæ§‹æ„ŸçŸ¥çš„è¨“ç·´ã€‚</p>
<h2 id="3-overview">3 Overview</h2>
<p><figure class="paper-figure"><img src="../../figures/2026-02-27/2602.22437/x3.png" loading="lazy"></figure> Figure 3 : veScale-FSDP overview.</p>
<p>To address both challenges of flexibility and performance, we present veScale-FSDP, a novel FSDP that combines the best of worlds.
Figure 3 provides the overview.
Model developers are given the freedom to develop sophisticated large models (e.g., with sparse MoE structures) and structure-aware optimizers (e.g., with non-element-wise operators) for achieving unprecedented model quality.
Meanwhile, the model/optimizer can be simply parallelized with PyTorch-native API fully_shard like FSDP2, without intrusively hacking model/optimizer code.
During parallelization, complex operators of models/optimizers can still enjoy single-device semantics, thanks to a proposed sharding format, dubbed RaggedShard that offers the flexibility to express arbitrary sharding granularity and arbitrary distribution across devices for each DTensor (Â§ 4 ).
Under the hood, RaggedShard DTensors are grouped for bucketed communication.
Toward optimal performance, their layouts are rearranged via a proposed planning algorithm which is derived from a NP-hard optimization problem.
The planned layouts are then mapped to a Distributed Buffer ( DBuffer ), a new primitive that achieves zero-copy and minimal overhead (Â§ 5 ), enabling efficient scaling up to 10K GPUs in real production deployments.</p>
<h2 id="4-raggedshard">4 RaggedShard çš„éˆæ´»æ€§</h2>
<p>æœ¬ç« ç¯€æå‡ºä¸€ç¨®æ–°ç©ä¸”é€šç”¨çš„åˆ†ç‰‡æ ¼å¼ RaggedShardï¼Œä»¥å¯¦ç¾ FSDP å°è¤‡é›œæ¨¡å‹å’Œçµæ§‹æ„ŸçŸ¥å„ªåŒ–å™¨çš„éˆæ´»æ€§ã€‚</p>
<p><figure class="paper-figure"><img src="../../figures/2026-02-27/2602.22437/x4.png" loading="lazy"></figure> åœ– 4ï¼šä¸åŒåˆ†ç‰‡æ ¼å¼çš„éˆæ´»æ€§æ¯”è¼ƒã€‚</p>
<p>ç¾æœ‰çš„åˆ†ç‰‡æ ¼å¼ã€‚ç¬¬äºŒç¨®æ ¼å¼æ˜¯ Row-wise (Even) Shardï¼Œå…¶ä¸­å¼µé‡æ²¿è‘—ä¸€å€‹ç¶­åº¦å‡å‹»åˆ†å‰²ï¼Œç›¸ç­‰å¤§å°çš„åˆ†ç‰‡åˆ†é…çµ¦æ¯å€‹è¨­å‚™ã€‚é€™ç¨®è¨­è¨ˆé€éåœ¨åˆ†ç‰‡å¼µé‡ä¸Šå•Ÿç”¨éå…ƒç´ ç´šè¨ˆç®—ï¼Œä¸¦å…è¨±é€é All2All é›†åˆé€²è¡Œç¶­åº¦é‡æ–°åˆ†é…ï¼Œå¾è€Œæé«˜äº†éˆæ´»æ€§ã€‚ç„¶è€Œï¼Œå®ƒä»ç„¶é¢è‡¨å€å¡Šç´šé‡åŒ–çš„æŒ‘æˆ°ï¼Œå› ç‚ºå‡å‹»åˆ†å‰²çš„åˆ†ç‰‡ä¸ä¸€å®šèˆ‡å€å¡Šé‚Šç•Œå°é½Šã€‚é€™ç¨®åˆ—å‘åˆ†ç‰‡æ ¼å¼æ˜¯ FSDP2 çš„åŸºç¤ã€‚</p>
<p>RaggedShard æ ¼å¼ã€‚å—åˆ°å–®è¨­å‚™ä¸Šçš„ JaggedTensor/NestedTensor çš„å•Ÿç™¼ [ jaggedtensor, nestedtensor, raggedtensors ]ï¼Œæˆ‘å€‘ç‚º DTensor æå‡ºäº† RaggedShard æ ¼å¼ï¼Œä»¥æä¾›éˆæ´»æ€§ä¾†è¡¨é”é€£çºŒè¨˜æ†¶ä¸­çš„ä»»æ„åˆ†ç‰‡ç²’åº¦ï¼ˆç”±é€£çºŒå…ƒç´ ã€è¡Œæˆ–å¹³é¢çµ„æˆçš„ä¸å¯åˆ†ç‰‡çš„åŸå­å–®ä½ï¼‰å’Œä»»æ„åˆ†ç‰‡åˆ†ä½ˆï¼ˆæ¯å€‹è¨­å‚™çš„å€å¡Šæ•¸é‡ï¼‰ã€‚åœ– 4 ä¸­çš„ç°¡å–®ä¾‹å­ä¸­ï¼Œå°‡ RaggedShard çš„ç²’åº¦è¨­å®šç‚ºä¸€å€‹å¼µé‡è¡Œï¼Œæœƒå¾—åˆ° Row-wise RaggedShardï¼Œå…¶è¡Œæ•¸åœ¨å„è¨­å‚™ä¸Šä¸åŒã€‚
åœ¨ Megatron-FSDP çš„æ¨¡å‹æª¢æŸ¥é»æ©Ÿåˆ¶ä¸­å·²æœ‰é¡ä¼¼çš„æ¦‚å¿µåŸå‹ã€‚</p>
<p>æœ€éˆæ´»çš„åˆ†ç‰‡æ ¼å¼æ˜¯ Block-wise RaggedShardï¼Œå…¶ä¸­åˆ†ç‰‡ç²’åº¦å®šç¾©ç‚ºå…·æœ‰å¯è‡ªè¨‚å½¢ç‹€çš„å¼µé‡å€å¡Šã€‚ä¾‹å¦‚ï¼Œä¸€å€‹å¼µé‡å¯èƒ½è¢«åˆ†å‰²æˆä¸‰å€‹äºŒç¶­å€å¡Šï¼Œä¸€å€‹å€å¡Šæ”¾åœ¨è¨­å‚™ 0 ä¸Šï¼Œå…©å€‹å€å¡Šæ”¾åœ¨è¨­å‚™ 1 ä¸Šï¼ˆè¦‹åœ– 4ï¼‰ã€‚é€™ç¨®æ ¼å¼ä¸åƒ…æ”¯æŒéå…ƒç´ ç´šè¨ˆç®—å’Œé«˜æ•ˆé‡æ–°åˆ†é…ï¼Œé‚„èƒ½å¤ ä»¥é‡åŒ–å€å¡Šèˆ‡åˆ†ç‰‡é‚Šç•Œå®Œç¾å°é½Šçš„æ–¹å¼é€²è¡Œå€å¡Šç´šé‡åŒ–ã€‚å¯¦éš›ä¸Šï¼ŒBlock-wise RaggedShard é€éä¸åŒçš„å€å¡Šå¤§å°é¸æ“‡ï¼Œå¯ä»¥æ­¸ç´æ‰€æœ‰å…ˆå‰çš„åˆ†ç‰‡æ ¼å¼ã€‚</p>
<p><figure class="paper-figure"><img src="../../figures/2026-02-27/2602.22437/x5.png" loading="lazy"></figure> åœ– 5ï¼šRaggedShard èˆ‡ç¾æœ‰çš„å‡å‹» Shard å°æ–¼äºŒç¶­ä¸¦è¡ŒåŒ–ï¼ˆå¦‚ FSDP $\times$ EPï¼ˆå°ˆå®¶ä¸¦è¡Œï¼‰ï¼‰çš„å¯çµ„åˆæ€§ã€‚</p>
<p>èˆ‡ç¾æœ‰åˆ†ç‰‡æ ¼å¼çš„çµ„åˆã€‚DTensor å·²è¢«å»£æ³›ç”¨æ–¼è¡¨é”å¼µé‡ä¸¦è¡ŒåŒ– (TP) [ shoeybi2019megatron ] å’Œå°ˆå®¶ä¸¦è¡ŒåŒ– (EP) [ lepikhin2020gshard ] ç­‰ä¸¦è¡ŒåŒ–ç­–ç•¥ä¸­çš„å¼µé‡åˆ†å€ã€‚å®ƒå…è¨±æ²¿è‘—é¸å®šç¶­åº¦ä½¿ç”¨è¤‡è£½ã€éƒ¨åˆ†å€¼æˆ–å‡å‹»åˆ†ç‰‡çš„æ”¾ç½®ä¾†è¡¨ç¤ºå¼µé‡ã€‚RaggedShard ä½œç‚ºé¡å¤–çš„ DTensor æ”¾ç½®æ“´å±•äº†é€™ç¨®èƒ½åŠ›ã€‚</p>
<p>ç‚ºäº†æ”¯æŒå¤šç¨®ä¸¦è¡ŒåŒ–ç­–ç•¥çš„çµ„åˆï¼ŒRaggedShard éœ€è¦èˆ‡ç¾æœ‰çš„ DTensor æ”¾ç½®ä¹¾æ·¨åœ°çµ„åˆã€‚RaggedShard èˆ‡è¤‡è£½å’Œéƒ¨åˆ†å€¼æ”¾ç½®éƒ½æ˜¯æ­£äº¤çš„ï¼ŒveScale-FSDP ç‰¹åˆ¥è™•ç† Shard æ”¾ç½®ã€‚å¯¦éš›ä¸Šï¼ŒTP ä½¿ç”¨ Shard(0) å’Œ Shard(1) é€²è¡Œåˆ—å‘å’Œåˆ—å‘å¼µé‡ä¸¦è¡ŒåŒ–ï¼›EP å¯ä»¥æ²¿è‘—å°ˆå®¶ç¶­åº¦ç·¨ç¢¼ç‚º Shard(0)ã€‚æŒ‰æ…£ä¾‹ï¼ŒEP/TP åœ¨ FSDP ä¹‹å‰æ‡‰ç”¨ã€‚ä½†åœ¨ PyTorch ä¸­ï¼ŒDTensor æ”¾ç½®åˆ—è¡¨çš„çµ„ç¹”é †åºèˆ‡æ¦‚å¿µæ‡‰ç”¨é †åºç›¸åï¼ˆè¦‹åœ– 5ï¼‰ï¼šé¡¯ç¤ºæ”¾ç½® ( RaggedShard, Shard(0) ) çš„å¼µé‡å…ˆæŒ‰ Shard(0) åˆ†å‰²ï¼Œå†æŒ‰ RaggedShard åˆ†å‰²ã€‚veScale-FSDP é€éä»¥ä¸‹æ–¹å¼èª¿å’Œé€™ä¸€é»ï¼š(i) å°æ–¼ Shard(0)ï¼Œå¼•å…¥äº†ä¸€å€‹å°ˆç”¨æ”¾ç½® StridedRaggedShardï¼Œè©²æ”¾ç½®æ”œå¸¶é‡æ–°æ’åº/æ­¥é•·å…ƒè³‡æ–™ä¸¦åŸ·è¡Œ</p>
<p>åŒæ™‚ï¼ŒRaggedShard ä½œç‚ºæ“´å±•çš„ DTensor æ”¾ç½®ï¼Œå¯ä»¥é€éç›´æ¥é‡ç”¨åŸºæ–¼ DTensor çš„æª¢æŸ¥é»æ£§ï¼ˆä¾‹å¦‚ï¼ŒPyTorch Distributed Checkpoint [ dcp ]ï¼‰ä¾†æä¾›æª¢æŸ¥é»åŠŸèƒ½ï¼Œç”¨æ–¼æ•…éšœæ¢å¾©ï¼Œä¸¦ä¸”ä¹Ÿèƒ½ç¹¼æ‰¿å…¶å„ªåŒ–ï¼Œä¾‹å¦‚ç„¡é€šè¨Šçš„åˆ†ç‰‡æª¢æŸ¥é»ã€‚</p>
<h2 id="5-grouped-raggedshard-for-performance">5 Grouped RaggedShard for Performance</h2>
<p>This section discusses how to group RaggedShard DTensors for efficient communication, as well as its NP-hardness for optimality and the underlying optimization.</p>
<p><figure class="paper-figure"><img src="../../figures/2026-02-27/2602.22437/x6.png" loading="lazy"></figure> Figure 6 : Grouped communication of RaggedShard DTensors.</p>
<p>Challenges for efficient communication. As well known in the systems community, collective communication relies on tensor bucketing or grouping to maximize network utilization [ li2020pytorch , zhao2023pytorch ] . The same applies to RaggedShard DTensors in FSDP. However, efficiently grouping RaggedShard tensors is non-trivial and naively approaches can lead to significant inefficiencies.
Figure 6 (a) illustrates three inefficient factors:
i) Sharded block that can happen when tensors are just concatenated back-to-back and put into communication buffer, without realizing that sharding boundary is within a certain block, which breaks the abstraction of Block-wise RaggedShard and incurs extra communication for quantization;
ii) Non-contiguous tensor memory that can happen when two ends of communication buffers are padded (to align collective preferred unit size [ wu2025terabyte , nccl16byte ] or equal size across devices [ nccl2025collective ] ), without realizing that such padding is within a certain tensor, which breaks the memory contiguousness and incurs interleaved copy overhead (e.g., similar to the copy-out after AllGather in Figure 2 );
and iii) Imbalanced load that can happen when different tensor sizes or block sizes or padding sizes are not aggregated to be equal across devices, which breaks the symmetry in collective communication (esp., Ring Algorithm) and ends up in underutilized networking.</p>
<p>Towards efficient communication. To efficiently group RaggedShard DTensors, we propose a two-step approach that addresses the above challenges: first permute tensors, and then pad between them rather than padding within individual tensors, as illustrated in Figure 6 (b). The key idea is to balance tensor and block sizes across devices while aligning block boundaries in the sharded communication buffer so that blocks are placed contiguously. This approach inevitably introduces some padding overhead, which must be carefully minimized to reduce both memory usage and communication volume.</p>
<p>Optimization problem formulation. Formally, the proposed approach can be formulated as an optimization problem.
Let ğ’¯ = T 1 , T 2 , â€¦ , T n \mathcal{T}={T_{1},T_{2},\ldots,T_{n}} denote a set of RaggedShard DTensors, which
are sharded across m m devices.
Each DTensor t âˆˆ ğ’¯ t\in\mathcal{T} has a block size of g t g_{t} , a total tensor size (in elements) e t e_{t} , and hence u t = e t / g t u_{t}=e_{t}/g_{t} sharding blocks.
We allocate a global communication buffer and place each t t as a contiguous memory interval [ â„“ t , r t ) [\ell_{t},r_{t}) .
The decision variables are the per-device buffer size S S and the interval endpoints { â„“ t , r t } t âˆˆ ğ’¯ {\ell_{t},r_{t}}_{t\in\mathcal{T}} .
Our goal is to minimize S S subject to the three factor constraints: Non-Sharded Block, Contiguous Tensor Memory, and strict Balanced Load (Figure 6 (b)):</p>
<table>
<thead>
<tr>
<th></th>
<th></th>
<th>min S , { â„“ t , r t } t âˆˆ ğ’¯ â¡ S \displaystyle\min_{S,{\ell_{t},r_{t}}_{t\in\mathcal{T}}}\ S</th>
<th></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td>s.t.</td>
<td>r t âˆ’ â„“ t = e t âˆ§ r t â‰¤ m â€‹ S , âˆ€ t âˆˆ ğ’¯ , \displaystyle r_{t}-\ell_{t}=e_{t}\ \land\ r_{t}\leq mS,\forall\,t\in\mathcal{T},</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>r t â‰¤ â„“ t â€² âˆ¨ r t â€² â‰¤ â„“ t , âˆ€ t â‰  t â€² âˆˆ ğ’¯ , \displaystyle r_{t}\leq\ell_{t^{\prime}}\ \lor\ r_{t^{\prime}}\leq\ell_{t},\forall\,t\neq t^{\prime}\in\mathcal{T},</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>k â€‹ S â‰¤ â„“ t âˆ¨ k â€‹ S â‰¥ r t âˆ¨ ( k â€‹ S âˆ’ â„“ t ) â‰¡ 0 ( mod g t ) , \displaystyle kS\leq\ell_{t}\ \lor\ kS\geq r_{t}\ \lor\ (kS-\ell_{t})\equiv 0\pmod{g_{t}},</td>
<td></td>
</tr>
<tr>
<td></td>
<td></td>
<td>âˆ€ t âˆˆ ğ’¯ , âˆ€ k = 1 , â€¦ , m \displaystyle\hskip 55.00008pt\forall\,t\in\mathcal{T},\ \forall\,k=1,\dots,m</td>
<td></td>
</tr>
</tbody>
</table>
<p>This optimization problem is NP-hard , as it can be reduced from the classic Partition problem [ garey1975complexity ] .
Although it can be formulated as an Integer Linear Programming (ILP) problem and solved using off-the-shelf solvers, such methods are impractical at scale. In practice, ILP solvers often take tens of minutes to generate a plan and may even trigger system timeouts. Given that user-defined FSDP wrapping can yield hundreds of parameter groups with diverse sharding block sizes, and deployments may span up to hundreds of thousands of devices, we instead design a polynomial-time heuristic algorithm that achieves near-optimal efficiency in practice.</p>
<p>Algorithm 1 Structure-aware planning for grouped communication of RaggedShard DTensors.</p>
<p>Heuristic-guided solution. veScale-FSDP proposes a polynomial-time dynamic-programming (DP) buffer-layout algorithm, guided by permutation heuristics that exploit the regularity of transformer models.
The optimization difficulty comes from tensor permutation: in principle, any permutation of tensors could be mapped into the buffer, and finding the global optimum would require exploring all permutations.
Fortunately, in practice, transformer parameters are highly structured: linear weights dominate the total parameter count, and sharding blocks are often consistent across layers.
To leverage this regularity, we explore three simple permutations: (i) default order of tensors; (ii) sorted order by sharding block sizes, and (iii) sorted order by tensor shapes.
Our statistics show that these orders yield optimal or near-optimal results,
so we adopt the default order for simplicity and ease of debugging.</p>
<p>Given the tensor order, the proposed algorithm applies a DP procedure to place tensors into a smallest global buffer while enforcing the aforementioned three factor constraints.
It enjoys a time complexity of O â€‹ ( | ğ’¯ | 2 â€‹ m â€‹ log â¡ ( E ) â€‹ log â¡ ( | ğ’¯ | â€‹ m ) ) O(|\mathcal{T}|^{2}m\log(E)\log(|\mathcal{T}|m)) .
Algorithm 1 presents the detail.</p>
<p>The core idea is a case analysis of how each tensor aligns with shard boundaries in any valid layout: (1) it lies entirely within a single local shard; (2) it straddles two adjacent shards, but doesnâ€™t contain a full shard; (3) it fully contains at least one shard. If every tensor falls into cases (1)â€“(2), feasibility is monotone in the shard size S S : whenever a layout exists for S S , it also exists for S + Î” S+\Delta (where Î” \Delta is the base alignment quantum). Because every shard includes an inter-tensor boundary, we can always absorb additional Î” \Delta as padding. If any tensor is in case (3), the feasible shard sizes must be multiples of L = LCM â¡ { g t âˆ£ t is in case (3) } L=\operatorname{LCM}{\,g_{t}\mid\text{$t$ is in case (3)}\,} . In this regime, feasibility is monotone over multiples: if k â€‹ L kL is feasible, then ( k + 1 ) â€‹ L (k{+}1)L is also feasible.
We therefore enumerate the case-(3) set and binary-search the minimal S S over the corresponding multiples, as shown in Line 17-21. To avoid exponentially enumerating all Case-(3) subsets, we sort tensors by element count and enumerate only the granularity prefixes, yielding a 2-approximation. Inside the feasibility checker, we define d â€‹ p â€‹ ( t , i ) dp(t,i) as the minimum number of devices (shards) required to store all atomic units up to the i i -th unit of tensor t t . Although the index space is as large as numerical space, d â€‹ p â€‹ ( t , i ) dp(t,i) is monotone within a tensor: d â€‹ p â€‹ ( t , i ) â‰¤ d â€‹ p â€‹ ( t , i + 1 ) dp(t,i)\leq dp(t,i{+}1) . So within each tensor there are at most m m distinct values. In Line 8-9, we exploit this by batching contiguous indices into segments and skipping d â€‹ p â€‹ ( t , âˆ— ) dp(t,*) evaluations at intermediate indices, achieving the stated time complexity.</p>
<p><figure class="paper-figure"><img src="../../figures/2026-02-27/2602.22437/x7.png" loading="lazy"></figure> Figure 7 : Distributed Buffer ( DBuffer ) for high performance communication. A 2D DBuffer for AllGatherâ€™ing parameters is shown; Reversely, a 2D DBuffer redistributing from ( Partial , Partial ) to ( Replicate , Shard ) implements 2D gradient reduction with ReduceScatter and AllReduce.</p>
<p>Distributed Buffer ( DBuffer ) Beyond grouping RaggedShard DTensors, the underlying communication buffer also plays a vital role in achieving high performance of communication, computation, and memory efficiency. To this end, veScale-FSDP proposes a new primitive, Distributed Buffer ( DBuffer ), to optimize the performance of grouped DTensors. Figure 7 shows the design.
First, inspired by DTensor, DBuffer provides global buffer semantics over an N N -dimensional device topology, with a sharding specification along each dimension, abstracting away the complexity of N N -D communication and operations.
Second, DBuffer takes a group of tensors and executes group-level operators rather than per-tensor operators.
For example, before communication, each tensor may need to launch its own CUDA kernels for add, scale, zero, or copy (which may differ across tensors), incurring fragmented compute overhead and blocking communication.
With DBuffer , identical kernels across tensors are fused before communication, reducing blocking time.
Third, DBuffer offers zero-copy before and after communication by leveraging RaggedShard â€™s planning algorithm and providing a persistent address mapping to each tensorâ€™s data pointer, minimizing memory footprint and fragmentation.
Lastly, DBuffer uses in-place communication and computation.</p>
<h2 id="6-evaluation">6 Evaluation</h2>
<p>Our evaluation answers the following questions:</p>
<ul>
<li>â€¢ How much does veScale-FSDP improve end-to-end training performance over all baseline systems (Â§ 6.1 )?</li>
<li>â€¢ How well does veScale-FSDP scale to large device counts (Â§ 6.2 ), in terms of weak scaling, strong scaling, and model size scaling?</li>
<li>â€¢ How are 8-bit Adam and Muon optimizer enabled by veScale-FSDPâ€™s customizable sharding granularity and RaggedShard DTensor, in both performance and development velocity (Â§ 6.3 )?</li>
<li>â€¢ How does veScale-FSDP planner minimize padding, and what is the algorithm overhead (Â§ 6.4 )?</li>
<li>â€¢ How much does each component of veScale-FSDP contribute to the training performance (Â§ 6.5 )?</li>
</ul>
<p>How much does veScale-FSDP improve end-to-end training performance over all baseline systems (Â§ 6.1 )?</p>
<p>How well does veScale-FSDP scale to large device counts (Â§ 6.2 ), in terms of weak scaling, strong scaling, and model size scaling?</p>
<p>How are 8-bit Adam and Muon optimizer enabled by veScale-FSDPâ€™s customizable sharding granularity and RaggedShard DTensor, in both performance and development velocity (Â§ 6.3 )?</p>
<p>How does veScale-FSDP planner minimize padding, and what is the algorithm overhead (Â§ 6.4 )?</p>
<p>How much does each component of veScale-FSDP contribute to the training performance (Â§ 6.5 )?</p>
<p>Hardware: We ran all experiments on a GPU cluster; each node contains 8 Ã— \times GPUs and connected with proprietary high-speed interconnect.</p>
<p>Implementation: veScale-FSDP is implemented with 7.6 K lines of code (LoC) in Python, transparently replacing the backend of FSDP2 while using the same PyTorch-native fully_shard API.
veScale-FSDP serves as a plug-and-play Python module, compatible with standard PyTorch distributed runtimes and a wide range of PyTorch versions.</p>
<p>Baselines: We compare veScale-FSDP against state-of-the-art open-source frameworks: DeepSpeed ZeRO v0.17.6 [ rajbhandari2020zero ] , PyTorch 2.7.1 FullyShardedDataParallel (FSDP1) [ zhao2023pytorch ] , PyTorch 2.7.1 fully_shard (FSDP2) [ pytorch2024fsdp2 ] , and Megatron-FSDP. For fairness, all frameworks are configured to use ZeRO-3 with mixed precision (i.e., FP32 master weights and BF16 forward/backward). Unless otherwise specified, veScale-FSDP employs element-wise sharding granularity and is compatible with standard training workflows.</p>
<p>Workloads: For the end-to-end comparison with the baselines (Â§ 6.1 ), we evaluate two state-of-the-art open-source models, LLaMA-3-70B [ dubey2024llama ] and GPT-OSS-120B [ agarwal2025gpt ] , as well as an internal MoE model. Under weak scaling, each device is statically assigned one batch; the sequence length is 4096 for the dense LLaMA model and 8192 for the MoE models. We use the AdamW optimizer by default. To avoid out-of-memory (OOM) errors for the baselines on GPT-OSS, we also report results using the SGD optimizer.</p>
<h3 id="61">6.1 ç«¯åˆ°ç«¯æ•ˆèƒ½</h3>
<p><figure class="paper-figure"><img src="../../figures/2026-02-27/2602.22437/x8.png" loading="lazy"></figure> åœ– 8ï¼šFSDP è¨“ç·´æ•ˆèƒ½ã€‚
ä¸Šæ’ï¼šæ­£è¦åŒ–èšåˆååé‡ï¼ˆtokens/sï¼‰ã€‚ä¸‹æ’ï¼šGPU å³°å€¼è¨˜æ†¶é«”ï¼ˆGBï¼‰ã€‚æˆ‘å€‘åœ¨ 128/256 å€‹ GPU ä¸Šæ¸¬è©¦ FSDP (ZeRO-3) ä»¥åŠå…·æœ‰ 2 å€å’Œ 4 å€è¤‡è£½çš„ HSDP (2<em>256, 4</em>256 å€‹ GPU)ã€‚</p>
<p>åœ– 8 æ¯”è¼ƒäº† veScale-FSDP èˆ‡åŸºæº–ç³»çµ±åœ¨ 1024 å€‹ GPU ä¸Šä¸‰å€‹ä»£è¡¨æ€§æ¨¡å‹çš„æ•ˆèƒ½ã€‚</p>
<p>ååé‡ï¼šåœ¨ MoE æ¨¡å‹ä¸Šï¼ŒveScale-FSDP æ¯”æ‰€æœ‰åŸºæº–ç³»çµ±å¿« 11 âˆ¼ \sim 66%ã€‚åœ¨ LLaMA-3-70B ä¸Šï¼ŒveScale-FSDP æ¯” DeepSpeedã€FSDP1 å’Œ FSDP2 å¿« 5%ï¼Œä¸¦ç•¥é ˜å…ˆ Megatron-FSDPã€‚æ›´é«˜çš„ååé‡ä¾†è‡ªæ–¼å„ªåŒ–çš„é€šè¨Šé‡ç–Šã€åŸºæ–¼ DBuffer çš„é›¶æ‹·è²é›†é«”é‹ç®—ä»¥åŠé¿å…å¡«å……é–‹éŠ·çš„éˆæ´»åˆ†ç‰‡ç²’åº¦ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒDeepSpeed ç”¢ç”Ÿåˆ†æ•£çš„é›†é«”é‹ç®— [ deepspeed_AG ]ï¼Œè€Œ FSDP1 å‘ˆç¾é€šè¨Šæ°£æ³¡ï¼Œå…¶ä¸­è³‡æ–™ç§»å‹•æ“ä½œé˜»æ­¢ NCCL é€²åº¦ï¼Œå°è‡´å…©å€‹ç³»çµ±ä¸­çš„ç¶²è·¯åˆ©ç”¨ä¸è¶³ã€‚FSDP2 ä¾è³´æ–¼æ¯åƒæ•¸ DTensor å‡å‹»åˆ†ç‰‡æ ¼å¼ï¼Œè©²æ ¼å¼åœ¨å…¨èšé›†å¾Œå¼•å…¥äº¤éŒ¯è¤‡è£½ï¼Œåœ¨è¦ç´„åˆ†æ•£å‰å¼•å…¥äº¤éŒ¯è¤‡è£½ï¼›é€™äº›è¤‡è£½åŠ èµ·ä¾†å¯æ¶ˆè€—è¨“ç·´è¿­ä»£çš„ 14%ï¼Œå› æ­¤é™ä½ååé‡ã€‚æ­¤å¤–ï¼ŒFSDP1 å’Œ FSDP2 å¿½è¦–äº† NCCL ä½å€å°é½Šæ³¨æ„äº‹é …ï¼Œåœ¨æŸäº›æƒ…æ³ä¸‹å°è‡´æ€§èƒ½æ˜é¡¯ä¸‹é™ [ wu2025terabyte ]ã€‚å„˜ç®¡ Megatron é‡å°é›¶æ‹·è²é›†é«”é‹ç®—é€²è¡Œäº†å„ªåŒ–ï¼Œä½†å…¶å›ºå®šçš„ Stride(0) åˆ†ç‰‡ç²’åº¦ï¼ˆç‚ºäº†èˆ‡ä¸Šæ¸¸ DTensor Shard(0) èªæ„ä¿æŒä¸€è‡´ä»¥é€²è¡Œåˆ†æ•£å¼æª¢æŸ¥é»ä¿å­˜ï¼‰åœ¨ MoE æ¨¡å‹ä¸­å°è‡´ 33% çš„ç·©è¡å¡«å……è†¨è„¹ï¼Œå› æ­¤æ¸›æ…¢äº†é›†é«”é‹ç®— [ megatron_fsdp ]ã€‚æˆ‘å€‘çš„å¯¦é©—è¡¨æ˜ï¼ŒveScale-FSDP é”åˆ°äº†ç·šæ€§å¯æ“´å±•æ€§ï¼›è©³ç´°åˆ†æè¦‹ç¬¬ 6.2 ç¯€ã€‚</p>
<p>è¨˜æ†¶é«”ï¼šåœ¨æ‰€æœ‰åŸºæº–æ¸¬è©¦ä¸­ï¼ŒveScale-FSDP å°‡å³°å€¼ä¿ç•™è¨˜æ†¶é«”æ¸›å°‘äº† 16â€“30%ã€‚è¨˜æ†¶é«”ç¯€çœä¾†è‡ªæ–¼ç¢ºå®šæ€§ã€æ‰¹è™•ç†çš„ DBuffer è¨˜æ†¶é«”ç®¡ç†ï¼šæˆ‘å€‘æ˜ç¢ºç®¡ç†æµä¾è³´ä»¥å¯¦ç¾å¯é æ¸¬çš„è¨˜æ†¶é«”é‡‹æ”¾ï¼Œä¸¦æ‰¹é‡é€²è¡Œåˆ†é…ä»¥æ¸›å°‘ç¢ç‰‡åŒ–ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼ŒDeepSpeed å’Œ FSDP1 å¾éš±å¼ record_stream [ per_parameter_shard_rfc ] ç¹¼æ‰¿éç¢ºå®šæ€§é‡‹æ”¾ï¼Œé€™é€šå¸¸æœƒé˜»æ­¢å¿«å–åˆ†é…å™¨é‡ç”¨ç·©è¡å€ï¼Œä½¿å³°å€¼ä¿ç•™è¨˜æ†¶é«”è†¨è„¹ 20%ã€‚ç›¸å°æ–¼ FSDP2 çš„æ¯åƒæ•¸ç«‹å³åˆ†é…ï¼Œæˆ‘å€‘çš„æ‰¹è™•ç†ç­–ç•¥é€²ä¸€æ­¥æ¸›å°‘äº† 12%ã€‚Megatron çš„å¡«å……è†¨è„¹ç·©è¡å€ä¸åƒ…é™ä½äº†é›†é«”é‹ç®—æ•ˆç‡ï¼Œé‚„åœ¨ MoE å¯¦é©—ä¸­å°‡å³°å€¼è¨˜æ†¶é«”æé«˜äº† 33%ï¼›å…¶æ··åˆç²¾åº¦æ”¯æ´ä¿ç•™ä½ç²¾åº¦ç·©è¡å€ï¼Œåœ¨ LLaMA-3 å¯¦é©—ä¸­æ¯” veScale-FSDP æ¶ˆè€— 24% æ›´å¤šè¨˜æ†¶é«”ã€‚è¼ƒä½çš„ä¿ç•™è¨˜æ†¶é«”ç›´æ¥è½‰åŒ–ç‚ºæ›´é«˜çš„ç«¯åˆ°ç«¯æ•ˆç‡ï¼šåœ¨é«˜è¨˜æ†¶é«”å£“åŠ›ä¸‹ï¼ŒPyTorch å¿«å–åˆ†é…å™¨æœƒç™¼å‡ºèˆ‡é©…å‹•ç¨‹å¼åŒæ­¥çš„è£ç½®é‡‹æ”¾ï¼Œå°è‡´è¨“ç·´åœæ»¯ã€‚åœ¨å¯æ“´å±•æ€§æ–¹é¢ï¼ŒveScale-FSDP çš„è¨˜æ†¶é«”å ç”¨é‡éš¨è‘— FSDP ç¾¤çµ„å¤§å°çš„å¢åŠ è€Œå–®èª¿éæ¸›ï¼Œä¸¦ä¸”åªéš¨è‘—è¤‡è£½å› å­é‚Šéš›å¢é•·ï¼Œç¬¦åˆæ“´å±•é æœŸã€‚GPT-OSS å‡ºç¾ä¸€å€‹å€¼å¾—æ³¨æ„çš„ä¾‹å¤–ï¼šFSDP2 åœ¨ 128 å€‹è£ç½®ä¸Šé€²è¡Œè¨“ç·´ï¼Œä½†åœ¨ 256 å€‹æ™‚ç™¼ç”Ÿ OOMã€‚DTensor ä¸­çš„æ¯åƒæ•¸åˆ†ç‰‡è¨­è¨ˆéœ€è¦å¡«å……ä»¥æ²¿è‘—åˆ†ç‰‡ç¶­åº¦å¼·åˆ¶å‡å‹»åˆ†å‰²ï¼›ç•¶ 128 å€‹å°ˆå®¶åˆ†æ•£åœ¨ 256 å€‹è£ç½®ä¸Šæ™‚ï¼Œå…¨èšé›†ç·©è¡å€å¯¦éš›ä¸Šç¿»å€ï¼Œè€—ç›¡è¨˜æ†¶é«”ã€‚é›–ç„¶ FSDP2 å…è¨±æ²¿è‘—å…¶ä»–ç¶­åº¦é€²è¡Œè‡ªè¨‚åˆ†ç‰‡ï¼Œä½†å®ƒéœ€è¦æ‰‹å‹•å¡«å……ï¼Œå› æ­¤ä½¿äº¤éŒ¯è¤‡è£½é–‹éŠ·ç¿»å€ï¼Œä½¿å…¶æˆæœ¬éé«˜ï¼ˆå›é¡§è¡¨ 1ï¼‰ã€‚</p>
<h3 id="62-scalability-and-composability">6.2 Scalability and Composability</h3>
<p><figure class="paper-figure"><img src="../../figures/2026-02-27/2602.22437/x9.png" loading="lazy"></figure> (a)</p>
<p>The flexibility of RaggedShard also enables seamless integration with complementary parallelization strategies such as expert parallelism (EP) [ lepikhin2020gshard ] .
Combining these techniques allows veScale-FSDP to efficiently scale training to internal models with up to 2.4T parameters on as many as 10K GPUs, as shown in Figure 9 . Note that we evaluate scalability of MoE, because MoE workloads are often more challenging to scale under FSDP: sparse expert computation lowers per-GPU compute while requires substantial all-gather/reduce-scatter traffic, making communication and padding overheads more significant.</p>
<p>Weak scaling: Figure LABEL:fig:weak_scale_10k presents the weak scaling performance of veScale-FSDP. We train an 800B-parameter MoE internal model on 1K to 8K GPUs while keeping the input size fixed at 2Kâ€“16K tokens per GPU. Across all input sizes, veScale-FSDP demonstrates near-linear scalability as the GPU count increases. This is expected since the communication cost of FSDP and the computation cost per GPU remain constant with respect to the number of GPUs, depending only on the model and input sizes. These results confirm the efficiency of veScale-FSDP on large-scale GPU clusters.</p>
<p>Strong scaling: We further evaluate the strong scaling performance of veScale-FSDP by fixing the global batch size to 16Mâ€“128M tokens and tuning expert and sequence parallelism configurations for each setting. Figures LABEL:fig:strong_scale_10k show the resulting throughput across different GPU numbers. veScale-FSDP scales linearly with a 128M-token global batch up to 10K GPUs, while still delivering a 3.4 Ã— \times throughput gain from 1K to 8K GPUs at a 16M-token global batch. When number of GPUs is small, each GPU processes enough tokens to fully overlap communication with computation, yielding near-linear scaling. However, as the GPU count continues to increase, fewer tokens are assigned per GPU per iteration, causing FSDP communicationâ€“â€“including parameter all-gather and gradient reduce-scatterâ€“â€“to dominate runtime. To mitigate this overhead, we adopt cross-node expert parallelism, which further reduces FSDP communication time. This optimization introduces higher computation cost due to token exchange and reduced kernel efficiency, resulting in the performance drop at very large scales.</p>
<p>Model scaling: We also evaluate model scaling by fixing the GPU count to 1K and increasing the model size from 400B to 2.4T parameters. With model sparsity constant and 8K training tokens per GPU, we scale both depth (number of layers) and width (intermediate dimensions) proportionally. Figure LABEL:fig:model_scale reports the effective Model FLOPS Utilization (MFU) per GPU as model size grows. Enabled by efficient memory management of DBuffer (Â§ 5 ), veScale-FSDP can train 2.4T-parameter models on only 1K GPUs without any performance degradation. In fact, MFU slightly improves with larger models due to the increased compute intensity and better utilization of GPU resources.</p>
<h3 id="63-8-bit-adam-muon">6.3 8-bit Adam å’Œ Muon å„ªåŒ–å™¨</h3>
<p>æˆ‘å€‘é€éå…©å€‹ä¾‹å­å±•ç¤º RaggedShard DTensor çš„éˆæ´»æ€§ï¼š8-bit Adam å’Œåˆ†æ•£å¼ Muon å„ªåŒ–å™¨ã€‚</p>
<p><strong>8-bit Adam å„ªåŒ–å™¨ã€‚</strong> 8-bit Adam [dettmers8] å°æ¢¯åº¦çµ±è¨ˆé‡æ‡‰ç”¨å€å¡Šç´š INT8 é‡åŒ–ï¼Œå¤§å¹…é™ä½å„ªåŒ–å™¨ç‹€æ…‹è¨˜æ†¶é«”ã€‚ç‚ºäº†å•Ÿç”¨ 8-bit Adamï¼ŒveScale-FSDP å…¬é–‹ orig_param_policy ä»‹é¢ï¼Œè®“ä½¿ç”¨è€…å¯ä»¥é‡å°æ¯å€‹åƒæ•¸è¨­å®šé‡åŒ–ç²’åº¦ã€‚åœ¨æˆ‘å€‘çš„è¨­å®šä¸­ï¼Œæˆ‘å€‘ä½¿ç”¨ $32 \times 32$ å€å¡Šä¸¦å°‡çŸ©é™£åƒæ•¸æŒ‡æ´¾åˆ° 32 åˆ—å€å¡Šç²’åº¦ã€‚ä½¿ç”¨æ­¤å¸ƒå±€ï¼Œæ¯å€‹è£ç½®å¯ä»¥ç¨ç«‹é‡åŒ–å…¶æœ¬åœ°åˆ†ç‰‡ï¼Œç„¡éœ€ä»»ä½•é€šè¨Šï¼Œä¸”å€å¡Šé‚Šç•Œç”± RaggedShard å®Œç¾ä¿ç•™ã€‚ç›¸æ¯”ä¹‹ä¸‹ï¼Œç¾æœ‰çš„ FSDP ç³»çµ±ç„¡æ³•åŸç”Ÿè¿½è¹¤æ­¤é¡å€å¡Šé‚Šç•Œï¼Œå› æ­¤å•Ÿç”¨å€å¡Šç´š 8-bit Adam é€šå¸¸éœ€è¦ä¾µå…¥æ€§ç³»çµ±è®Šæ›´æˆ–æ‰‹å‹•é›†åˆé«”ä¾†äº¤æ›é‡åŒ–ä¸­ç¹¼è³‡æ–™ï¼Œæ—¢å¢åŠ è¤‡é›œåº¦åˆå¸¶ä¾†é¡å¤–é–‹éŠ·ã€‚</p>
<p><figure class="paper-figure"><img src="../../figures/2026-02-27/2602.22437/x12.png" loading="lazy"></figure> (a)</p>
<p>æˆ‘å€‘ä½¿ç”¨ veScale-FSDP ä»¥å°‘æ•¸å¹¾è¡Œç¨‹å¼ç¢¼å¯¦ä½œ 8-bit Adamï¼Œä¸¦åœ¨åœ– LABEL:fig:adam_loss ä¸­æä¾›è©•ä¼°ã€‚æˆ‘å€‘æ¯”è¼ƒåˆ†æ•£å¼è³‡æ–™å¹³è¡ŒåŒ– (DDP) å’Œ veScale-FSDP ä¸‹çš„ 8-bit Adamã€‚æå¤±æ›²ç·šç·Šå¯†è¿½è¹¤ï¼Œä¼´éš¨è‘—é™ä½ç²¾åº¦å„ªåŒ–å™¨ç‹€æ…‹ç‰¹æœ‰çš„å¶ç™¼å°–å³°ã€‚å°å·®ç•°ä¾†è‡ªæ¢¯åº¦åŒ–ç°¡æ’ç¨‹ï¼šDDP ä½¿ç”¨åˆ†æ¡¶ all-reduceï¼Œè€Œ veScale-FSDP åŸ·è¡Œå±¤ç´š reduce-scatterã€‚ï¼ˆè«‹æ³¨æ„åœ– 10 ä¸­çš„æå¤±æ›²ç·šç„¡æ³•ç›´æ¥æ¯”è¼ƒï¼šå°æ–¼ 8-bit Adamï¼Œæˆ‘å€‘ä½¿ç”¨è¼ƒå°çš„å­¸ç¿’ç‡ä»¥æ¸›è¼•é™ä½ç²¾åº¦ä¸­çš„æº¢ä½/ä¸‹æº¢ã€‚ï¼‰</p>
<p>ç®—æ³• 2 RaggedShard åˆ†æ•£å¼ Muon</p>
<p><strong>åˆ†æ•£å¼ Muon å„ªåŒ–å™¨ã€‚</strong> Muon çš„çŸ©é™£ç¬¦è™Ÿå‰ç½®æ¢ä»¶å™¨ï¼ˆä¾‹å¦‚ Newtonâ€“Schulzï¼‰éœ€è¦å…·æœ‰å…¶åŸå§‹å½¢ç‹€çš„å®Œæ•´ 2D åƒæ•¸çŸ©é™£ã€‚ç®—æ³• 2 æ¦‚è¿°ç”± RaggedShard å•Ÿç”¨çš„åˆ†æ•£å¼ Muon å„ªåŒ–å™¨ã€‚å¾—ç›Šæ–¼ RaggedShard å°éå‡å‹»åˆ†ç‰‡çš„æ”¯æ´èƒ½åŠ›ï¼Œä½¿ç”¨è€…å¯ä»¥ä»¥ç°¡æ½”çš„ SPMD æ–¹å¼æ’°å¯« Muon çš„åƒæ•¸è’é›†æ­¥é©Ÿï¼šåœ¨é‡æ–°åˆ†ä½ˆå¾Œï¼Œåªæœ‰æ ¹ç§©ä¿æŒå®Œæ•´çš„ 2D åƒæ•¸ï¼Œå› æ­¤ Newtonâ€“Schulz æ›´æ–°åœ¨å…¶ä»–ç§©ä¸Šè®Šæˆç„¡æ“ä½œã€‚å¦‚ç¬¬ 4â€“7 è¡Œæ‰€ç¤ºï¼Œç®—æ³•é€éè² è¼‰å¹³è¡¡é¸æ“‡æ ¹ï¼Œä¸¦ä½¿ç”¨å¸¶ RaggedShard ä½ç½®çš„æ¨™æº– DTensor é‡æ–°åˆ†ä½ˆä¾†è§£åˆ†ç‰‡ã€‚ç¬¬ 8â€“9 è¡Œåªåœ¨æŒæœ‰å®Œæ•´å¼µé‡çš„æ ¹ä¸ŠåŸ·è¡Œ Muon çŸ©é™£åè¦†é‹ç®—ã€‚æœ€å¾Œï¼Œç¬¬ 10â€“12 è¡Œå°‡æ›´æ–°é‡æ–°åˆ†ä½ˆå›åŸå§‹è£ç½®ä¸¦æ‡‰ç”¨å®ƒã€‚å› æ­¤ï¼Œä½¿ç”¨è€…ä¸éœ€è¦è™•ç†è¤‡é›œçš„é€šè¨Šé‚è¼¯ï¼Œä¸¦å¯é€²ä¸€æ­¥é€ééåŒæ­¥ redistribute ä¾†é‡ç–Šé€šè¨Šèˆ‡è¨ˆç®—ã€‚æ­¤å¤–ï¼Œæˆ‘å€‘æœ€ä½³åŒ–çš„ Muon é€éåˆ©ç”¨é€šè¨Š-è¨ˆç®—é‡ç–Šå’Œä½¿ç”¨ torch.compile ä¾†é€²ä¸€æ­¥å¢åŠ è¨ˆç®—å¯†åº¦ï¼Œåœ¨ 256 GPU ä¸Šé”åˆ° 47.3% MFUã€‚</p>
<p>æˆ‘å€‘ä½¿ç”¨ veScale-FSDP ä»¥å°‘æ•¸å¹¾è¡Œç¨‹å¼ç¢¼å¯¦ä½œåˆ†æ•£å¼ Muonï¼Œä¸¦åœ¨åœ– LABEL:fig:muon_loss ä¸­æä¾›è©•ä¼°ã€‚æˆ‘å€‘æ¯”è¼ƒ Muon å’Œ AdamW çš„æå¤±æ›²ç·šï¼šå…©å€‹ Muon åŸ·è¡Œï¼ˆveScale-FSDP å’Œ DDPï¼‰ç·Šå¯†åŒ¹é…ï¼Œä¸” Muon æ¯” AdamW æ”¶æ–‚æ›´å¿«ï¼Œåœ¨è¨“ç·´ç´„ 80B å€‹ token å¾Œç©©å®šåœ¨ä½ç´„ 0.01 çš„æå¤±ï¼Œé€™èˆ‡å…ˆå‰çµæœ [wen2025fantastic] ä¸€è‡´ã€‚</p>
<h3 id="64">6.4 è¦åŠƒå“è³ª</h3>
<p>è¦åŠƒæ¼”ç®—æ³•ï¼ˆAlgorithm 1ï¼‰çš„ä¸»è¦è¨­è¨ˆç›®æ¨™æ˜¯å•Ÿç”¨ä»»æ„ç²’åº¦çš„ RaggedShardï¼ŒåŒæ™‚æœ€å°åŒ–å¡«å……é–‹éŠ·ï¼Œå¾è€Œæ¸›å°‘é€šè¨Šé‡ã€‚
è¦åŠƒæ¼”ç®—æ³•çš„å“è³ªå¯ä»¥ç›´æ¥é€éå¡«å……å¤§å°ä¾†è©•ä¼°ã€‚
æˆ‘å€‘é€éåœ¨ä¸åŒè£ç½®æ•¸é‡ä¸‹å° DeepSeek-v3-671B å’Œ GPT-OSS-120B é€²è¡ŒåŸºæº–æ¸¬è©¦ä¾†è©•ä¼°ã€‚éµå¾ª DeepSeek é¢¨æ ¼çš„é‡åŒ–æ–¹æ¡ˆï¼Œæˆ‘å€‘åªé‡åŒ– FFN æ¬Šé‡ï¼ˆå¤§éƒ¨åˆ†åƒæ•¸ï¼‰ï¼Œä¸¦åœ¨ 128ã€16ã€1 ä¸Šæƒæ expert-MLP çŸ©é™£çš„åˆ—ç²’åº¦ã€‚128 åˆ—çš„è¨­ç½®å†ç¾äº† DeepSeek çš„ 128 Ã— \times 128 å¹³é‹ªï¼ˆå³æ¬Šé‡å¯ä»¥åˆ‡å‰²æˆ 128 Ã— \times 128 å¡Šï¼‰ã€‚ç„¶å¾Œæˆ‘å€‘å ±å‘Šæ‰€å¾—çš„ç›¸å°å¡«å……æ¯”ç‡ï¼Œä¸¦åˆ†æé¡å¤–å¡«å……çš„æ ¹æœ¬åŸå› ã€‚</p>
<p><figure class="paper-figure"><img src="../../figures/2026-02-27/2602.22437/x14.png" loading="lazy"></figure> (a)</p>
<p>Figure LABEL:fig:deepseek_v3_padding å’Œ LABEL:fig:gpt_oss_padding é¡¯ç¤ºï¼Œå°æ–¼ 1 Ã— \times å’Œ 16 Ã— \times åˆ—ç²’åº¦ï¼ŒveScale-FSDP åœ¨æ‰€æœ‰ FSDP å¤§å°ä¸Šéƒ½èƒ½å¤ ä½¿å…©å€‹æ¨¡å‹çš„å¡«å……é–‹éŠ·ä¿æŒåœ¨ 3% ä»¥ä¸‹ã€‚å°æ–¼ 128 Ã— \times åˆ—ï¼ŒDeepSeek-v3 å¤§éƒ¨åˆ†æƒ…æ³ä¿æŒåœ¨ 3% ä»¥ä¸‹ï¼Œæˆé•·æº«å’Œï¼Œè€Œ GPT-OSS å‘ˆç¾éšæ¢¯å¼æ³¢å‹•ï¼Œå³°å€¼é«˜é” 18%ã€‚GPT-OSS å°‡æ‰€æœ‰ expert èåˆåˆ°å–®ä¸€åƒæ•¸å¼µé‡ä¸­ï¼Œè€Œ DeepSeek-V3 å°‡æ¯å€‹ expert å¯¦ç¾ç‚ºç¨ç«‹åƒæ•¸ï¼›é€™ä½¿å¾— MLP ä¹‹é–“çš„é€ expert å¡«å……æˆç‚ºå¯èƒ½ï¼Œé€²è€Œæ”¾é¬†äº†å…¨åŸŸå¡«å……ç´„æŸã€‚æ³¢å‹•è¡Œç‚ºæ˜¯é æœŸçš„ï¼šæ¯å€‹çŸ©é™£å¿…é ˆæŒ‰ç…§ç”±ä»¥ä¸‹å› ç´ æ±ºå®šçš„é›¢æ•£é‡å­è·¨è¶Šåˆ†ç‰‡ç¾¤çµ„é€²è¡Œåˆ†å‰²ï¼š(i) ç²’åº¦å–®ä½ï¼ˆä¾‹å¦‚åˆ—ï¼‰å’Œ (ii) NCCL ç”¨æ–¼é«˜æ•ˆèƒ½é›†é«”é€šè¨Šçš„å¶æ•¸è¼¸å…¥å°é½Šã€‚æœ‰æ•ˆçš„åˆ†ç‰‡å¤§å°å› æ­¤è¢«å››æ¨äº”å…¥åˆ°é€™äº›ç²’åº¦çš„æœ€å°å…¬å€æ•¸ï¼›ç•¶ç¾¤çµ„å¤§å°è·¨è¶Šå€æ•¸æ™‚ï¼Œæ¯å€‹è£ç½®çš„åˆ†ç‰‡å¤§å°æœƒè·³èºï¼Œç”¢ç”Ÿè§€å¯Ÿåˆ°çš„å³°å€¼ã€‚</p>
<p>æœ€å¾Œï¼Œæˆ‘å€‘ä¹Ÿè©•ä¼°äº†è¦åŠƒæ¼”ç®—æ³•æœ¬èº«çš„é–‹éŠ·ï¼šåœ¨æ‰€æœ‰å¯¦é©—ä¸­ï¼Œæ¼”ç®—æ³•é‹è¡Œæ™‚é–“å°‘æ–¼ 0.3 ç§’ï¼Œé€™åœ¨åˆ†æ•£å¼è¨“ç·´åˆå§‹åŒ–ä¸­æ˜¯ä¸€æ¬¡æ€§ä¸”å¯å¿½ç•¥çš„ã€‚</p>
<h3 id="65-performance-breakdown">6.5 Performance Breakdown</h3>
<p>Table 2 : Component ablation for 8-bit Adam, in terms of normalized throughput when disabling each component. N/A means impossible without intrusively changing model/optimizer code or managing custom collectives.</p>
<p>To quantify the benefit of each component, we ablate veScale-FSDP by disabling one component at a time and report the resulting throughput, normalized to the full system. We run this study on 32 GPUs when training a GPT-OSS-style model with 8-bit Adam.</p>
<p>Table 2 shows that DBuffer and the Planning Algorithm account for most of the realized speedups: disabling them reduces throughput to 92.8% and 65.4%, respectively. In contrast, RaggedShard is not just an optimization; it is the abstraction that makes block-wise 8-bit Adam usable without intrusive model/optimizer changes or hand-written collectives. Specifically:</p>
<ul>
<li>â€¢ DBuffer . Disabling DBuffer drops throughput by 7.2%, reflecting the copy-in/copy-out overhead around collectives when communication buffers require copy.</li>
<li>â€¢ Planning Algorithm. Disabling the planning drops throughput by 34.6% because quantization blocks are no longer guaranteed to be fully contained within a deviceâ€™s local shard. The system then falls back to DTensor redistribution to assemble the required optimizer states before per-block quantization, incurring substantial extra communication overhead.</li>
<li>â€¢ RaggedShard DTensor. Disabling RaggedShard makes it effectively non-runnable: users must either (i) carefully change every model and optimizer tensor so that 32 Ã— 32 32\times 32 block boundaries align with shard boundaries, or (ii) manually implement complex collectives (e.g., per-block metadata exchange and state gathering) to recover block-wise semantics. We therefore report this setting as N/A to indicate itâ€™s not meaningfully usable.</li>
</ul>
<p>DBuffer . Disabling DBuffer drops throughput by 7.2%, reflecting the copy-in/copy-out overhead around collectives when communication buffers require copy.</p>
<p>Planning Algorithm. Disabling the planning drops throughput by 34.6% because quantization blocks are no longer guaranteed to be fully contained within a deviceâ€™s local shard. The system then falls back to DTensor redistribution to assemble the required optimizer states before per-block quantization, incurring substantial extra communication overhead.</p>
<p>RaggedShard DTensor. Disabling RaggedShard makes it effectively non-runnable: users must either (i) carefully change every model and optimizer tensor so that 32 Ã— 32 32\times 32 block boundaries align with shard boundaries, or (ii) manually implement complex collectives (e.g., per-block metadata exchange and state gathering) to recover block-wise semantics. We therefore report this setting as N/A to indicate itâ€™s not meaningfully usable.</p>
<h2 id="7">7 ç¶“é©—æ•™è¨“</h2>
<p>åœ¨ä½¿ç”¨è¶…é 10,000 å€‹ GPU çš„çœŸå¯¦å·¥æ¥­å·¥ä½œè² è¼‰ä¸­éƒ¨ç½² veScale-FSDP æœŸé–“ï¼Œæˆ‘å€‘ç¸½çµäº†ä»¥ä¸‹é—œéµç¶“é©—æ•™è¨“ã€‚</p>
<p><strong>ç¶“é©—æ•™è¨“-1ï¼šå°è¦æ¨¡å·¥ä½œè² è¼‰å¯é æ¸¬å¤§è¦æ¨¡æ€§èƒ½ã€‚</strong> FSDP åŸºç¤å·¥ä½œè² è¼‰çš„æ€§èƒ½å¯ä»¥ä½¿ç”¨æ¯å±¤çš„è¨ˆç®—æ™‚é–“å’Œ FSDP é€šè¨Šæ™‚é–“ç²¾ç¢ºä¼°è¨ˆã€‚è¨ˆç®—å®Œå…¨ç™¼ç”Ÿåœ¨æ¯å€‹ GPU å…§ï¼Œç•¶ GPU æ•¸é‡å¢åŠ æ™‚ï¼ŒFSDP é€šè¨Šæ™‚é–“åŸºæœ¬ä¿æŒä¸è®Šã€‚é€™ä¸€è§€å¯Ÿçµæœé€šéæˆ‘å€‘çš„å¼±æ“´å±•å¯¦é©—ï¼ˆÂ§ 6ï¼‰å¾—åˆ°é©—è­‰ã€‚åœ¨å¯¦è¸ä¸­ï¼Œæˆ‘å€‘åœ¨ç´„ 64 å€‹ GPU ä¸Šå° veScale-FSDP é€²è¡Œæ€§èƒ½å‰–æï¼Œä¸¦å¤–æ¨è‡³æ•¸åƒå€‹ GPUï¼Œå–å¾—ç›¸ä¼¼çš„çµæœã€‚</p>
<p>æ­¤å¤–æ¨å‡è¨­å‰–æé‹è¡Œæ™‚çš„ç¶²è·¯è¡Œç‚ºèˆ‡ç›®æ¨™è¦æ¨¡ç›¸ä¼¼ï¼šå¯æ¯”è¼ƒçš„ç¶²è·¯æ‹“æ’²ã€ç›¸åŒçš„é›†åˆç®—æ³•/å”è­°ï¼Œä»¥åŠè¶³å¤ å¤§çš„å·¥ä½œè² è¼‰ä»¥é”åˆ°é »å¯¬é£½å’Œã€‚ç‚ºé€²ä¸€æ­¥æ”¹é€²å¤§è¦æ¨¡ä¸‹çš„å¯é æ¸¬æ€§ï¼Œæˆ‘å€‘ä½¿ç”¨é¡å¤–çš„ä¸¦è¡ŒåŒ–ï¼ˆä¾‹å¦‚ HSDP/EPï¼‰ä¾†é™åˆ¶é›†åˆçµ„çš„å¤§å°ï¼Œé˜²æ­¢å»¶é²è®ŠåŒ–æ›´å¤§çš„éåº¦é¾å¤§é›†åˆã€‚</p>
<p><strong>ç¶“é©—æ•™è¨“-2ï¼šåœ¨å·¨äººçš„è‚©è†€ä¸Šè¨­è¨ˆç³»çµ±æŠ½è±¡ã€‚</strong> DTensor æä¾›å¼·å¤§çš„æŠ½è±¡ï¼Œå·²æ”¯æ´å»£æ³›çš„ä¸¦è¡ŒåŒ–æŠ€è¡“ã€‚é€šéåœ¨ DTensor ä¹‹ä¸Šè¨­è¨ˆæ–°çš„æŠ½è±¡ï¼Œæˆ‘å€‘å¯ä»¥ç„¡ç¸«æ•´åˆç¾æœ‰çš„ä¸¦è¡ŒåŒ–ç­–ç•¥ã€‚åœ¨æˆ‘å€‘çš„å·¥ä½œä¸­ï¼ŒRaggedShard placement è¢«å¯¦ç¾ç‚º DTensor ä¸Šçš„å¯é¸ placementï¼Œä½¿å¾—å·²å»ºç«‹çš„åŸºç¤è¨­æ–½ï¼ˆå¦‚å¼µé‡å’Œå°ˆå®¶ä¸¦è¡Œï¼‰ä»¥åŠæˆç†Ÿçš„è¨“ç·´å·¥å…·ï¼ˆå¦‚åˆ†æ•£å¼æª¢æŸ¥é» [dcp]ï¼‰èƒ½å¤ è¼•é¬†å”ä½œã€‚é€™ç¨®æ–¹æ³•æœ€å°åŒ–äº†å·¥ç¨‹åŠªåŠ›ï¼ŒåŒæ™‚ç‚ºæ›´å»£æ³›çš„ç¤¾ç¾¤é€ ç¦çš„å…±äº«ç”Ÿæ…‹ç³»çµ±åšå‡ºè²¢ç»ã€‚äº‹å¯¦ä¸Šï¼ŒRaggedShard å·²ç¶“å‡ºç¾åœ¨ PyTorch çš„å®˜æ–¹è·¯ç·šåœ– [pytorch_2026_h1_roadmap] ä¸Šä½œç‚ºè¨ˆåŠƒä¸­çš„åŠŸèƒ½ã€‚</p>
<p><strong>ç¶“é©—æ•™è¨“-3ï¼šè§£è€¦çš„æ¨¡å‹å®šç¾©èˆ‡ç³»çµ±æœ€ä½³åŒ–è‡³é—œé‡è¦ã€‚</strong> æ¨¡å‹æ¶æ§‹çš„å¿«é€Ÿæ¼”é€²éœ€è¦é »ç¹æ›´æ–°æ¨¡å‹å®šç¾©ã€‚ç„¶è€Œï¼Œç¾æœ‰æ¡†æ¶ï¼ˆå¦‚ Megatron-LMï¼‰å°‡ç³»çµ±ç´šä¸¦è¡ŒåŒ–æœ€ä½³åŒ–èˆ‡æ¨¡å‹ç¨‹å¼ç¢¼ç·Šå¯†è€¦åˆï¼Œä½¿ç ”ç©¶äººå“¡é›£ä»¥ä¿®æ”¹æˆ–æ“´å±•æ¶æ§‹ã€‚åœ¨ veScale-FSDP ä¸­ï¼Œæˆ‘å€‘å°‡æ¨¡å‹å®šç¾©èˆ‡ç³»çµ±æ¡†æ¶è§£è€¦ï¼Œä½¿ç ”ç©¶äººå“¡èƒ½å¤ å°ˆæ³¨æ–¼æ¨¡å‹è¨­è¨ˆï¼ŒåŒæ™‚åœ¨æœ€å¤š 10,000 å€‹ GPU ä¸Šä¿æŒç·šæ€§å¯æ“´å±•æ€§ã€‚é€™ç¨®åˆ†é›¢å¤§å¤§ç°¡åŒ–äº†æ¨¡å‹é–‹ç™¼ï¼Œä¸¦åŠ é€Ÿäº†æ¶æ§‹å‰µæ–°ã€‚</p>
<h2 id="8">8 çµè«–</h2>
<p>veScale-FSDP æ˜¯ä¸€å€‹å¯æ“´å±•çš„è¨“ç·´ç³»çµ±ï¼Œé€é RaggedShard æŠ½è±¡åŒ–å’Œçµæ§‹æ„ŸçŸ¥è¦åŠƒæ¼”ç®—æ³•çš„çµåˆï¼Œå¯¦ç¾é«˜éˆæ´»æ€§å’Œé«˜æ•ˆèƒ½ï¼Œæœ€å¤§åŒ– GPU ä½¿ç”¨ç‡ã€‚å¯¦é©—è­‰æ˜ veScale-FSDP èƒ½ç„¡ç¸«æ•´åˆæ–°èˆˆæŠ€è¡“å¦‚ Muon æœ€ä½³åŒ–å™¨ï¼Œé¡¯è‘—å„ªæ–¼ç¾æœ‰ç³»çµ±ï¼Œå¯¦ç¾ 5 âˆ¼ 66% çš„ååé‡æå‡å’Œ 16 âˆ¼ 30% çš„è¨˜æ†¶é«”ä½¿ç”¨ç‡é™ä½ï¼ŒåŒæ™‚èƒ½æœ‰æ•ˆæ“´å±•è‡³æ•¸è¬å€‹ GPUã€‚</p>
<h2 id="9">9 è‡´è¬</h2>
<p>å¦‚æœæ²’æœ‰æˆ‘å€‘åœ˜éšŠæˆå“¡å’ŒåŒäº‹çš„å·¨å¤§æ”¯æŒèˆ‡å”ä½œï¼ŒveScale-FSDP ä¸å¯èƒ½é¢ä¸–ã€‚æˆ‘å€‘è¬¹å‘ä»–å€‘ï¼ˆé †åºä¸åˆ†å…ˆå¾Œï¼›æ­¤åˆ—è¡¨ä¸¦éå®Œæ•´ï¼‰è‡´ä»¥èª æ‘¯çš„æ„Ÿè¬ï¼š</p>
<ul>
<li>â€¢ veScale æˆå“¡ï¼šHongrui Zhan, Ziyi Zhang, Hao Feng</li>
<li>â€¢ ByteDance åŒäº‹ï¼šJianyu Jiang, Chenyuan Wang, Cesar Andres Stuardo Moraga, Juntao Zhao, Bin Jia, Chengye Li, Zhongkai Zhao, Shixiong Zhao, Tiantian Fan, Hanshi Sun, Wenlei Bao, Shixun Wu, Zhekun Zhang, Yanbo Liang, Li-wen Chang, Jun Wang, Cheng Li, Li Han, Heng Zhang, Zhenbo Sun, Bo Liu, Xiaonan Nie, Ru Zhang, Hao Gong, Zuquan Song, Yucheng Nie, Jiawei Wu, Hongpeng Guo, Xinyi Di</li>
</ul>
<p>veScale æˆå“¡ï¼šHongrui Zhan, Ziyi Zhang, Hao Feng</p>
<p>ByteDance åŒäº‹ï¼šJianyu Jiang, Chenyuan Wang, Cesar Andres Stuardo Moraga, Juntao Zhao, Bin Jia, Chengye Li, Zhongkai Zhao, Shixiong Zhao, Tiantian Fan, Hanshi Sun, Wenlei Bao, Shixun Wu, Zhekun Zhang, Yanbo Liang, Li-wen Chang, Jun Wang, Cheng Li, Li Han, Heng Zhang, Zhenbo Sun, Bo Liu, Xiaonan Nie, Ru Zhang, Hao Gong, Zuquan Song, Yucheng Nie, Jiawei Wu, Hongpeng Guo, Xinyi Di</p>
<p>åŒæ¨£é‡è¦çš„æ˜¯ï¼Œæˆ‘å€‘æ„Ÿè¬ TorchTitan åœ˜éšŠçš„æ‰€æœ‰æˆå“¡å’Œ Edward Z. Yang åœ¨é–‹æºç¤¾ç¾¤å…§çš„æ·±å…¥è¨è«–èˆ‡å”ä½œã€‚</p>
<h2 id="_1">åƒè€ƒè³‡æ–™</h2>
  
</div>


  </main>

  <footer class="site-footer">
    <div class="container">
      <p>æ¯æ—¥è‡ªå‹•æŠ“å– <a href="https://huggingface.co/papers" target="_blank">HuggingFace Daily Papers</a>ï¼Œä»¥ Claude AI ç¿»è­¯ç‚ºç¹é«”ä¸­æ–‡ã€‚</p>
    </div>
  </footer>
</body>
</html>