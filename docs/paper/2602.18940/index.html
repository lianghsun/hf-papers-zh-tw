<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>DREAMï¼šå…·æœ‰ä»£ç†åº¦é‡çš„æ·±åº¦ç ”ç©¶è©•ä¼° â€” HF Papers ç¹ä¸­</title>
  <link rel="stylesheet" href="../../assets/style.css">
  
</head>
<body>
  <header class="site-header">
    <div class="container">
      <a href="../../index.html" class="site-logo">ğŸ“„ HF Papers ç¹ä¸­</a>
      <nav>
        <a href="../../index.html">é¦–é </a>
        <a href="https://huggingface.co/papers" target="_blank" rel="noopener">HuggingFace</a>
      </nav>
    </div>
  </header>

  <main class="container">
    

<div class="paper-page-header">
  <a href="../../2026-02-25/index.html" style="font-size:0.85rem;color:var(--text-muted);">
    â† 2026-02-25 è«–æ–‡åˆ—è¡¨
  </a>
  <h1 style="margin-top:0.75rem;">DREAMï¼šå…·æœ‰ä»£ç†åº¦é‡çš„æ·±åº¦ç ”ç©¶è©•ä¼°</h1>
  
  <div class="en-title">DREAM: Deep Research Evaluation with Agentic Metrics</div>
  

  <div class="paper-meta">
    
    <span>Elad Ben Avraham, Changhao Li, Ron Dorfman, Roy Ganz, Oren Nuriel, Amir Dudai, Aviad Aberdam, Noah Flynn, Elman Mansimov, Adi Kalyanpur, Ron Litman</span>
    
    <span>arXiv: <a href="https://arxiv.org/abs/2602.18940" target="_blank">2602.18940</a></span>
    
    <span style="color:var(--text-muted);font-size:0.8rem;">
      ä¾†æºï¼šPDF + DotsOCR
    </span>
    
  </div>

  <div class="paper-links">
    <a href="https://arxiv.org/pdf/2602.18940" target="_blank" rel="noopener" class="btn btn-primary">PDF åŸæ–‡</a>
    <a href="https://arxiv.org/abs/2602.18940" target="_blank" rel="noopener" class="btn btn-outline">arXiv</a>
    <a href="https://huggingface.co/papers/2602.18940" target="_blank" rel="noopener" class="btn btn-outline">HF é é¢</a>
  </div>

  <div class="tags">
    <span class="tag domain">NLP</span>
    <span class="tag method">Agent</span><span class="tag method">Tool-use</span><span class="tag method">LLM-based evaluation</span>
    <span class="tag task">Report Evaluation</span><span class="tag task">Research Quality Assessment</span><span class="tag task">Factual Verification</span>
    
  </div>
</div>

<!-- Abstract -->
<div class="abstract-box">
  <h2>æ‘˜è¦</h2>
  <p># æ·±åº¦ç ”ç©¶ä»£ç†çš„è©•ä¼°æ¡†æ¶

æ·±åº¦ç ”ç©¶ä»£ç†å¯ä»¥ç”Ÿæˆåˆ†æå¸«ç´šåˆ¥çš„å ±å‘Šï¼Œä½†ç”±æ–¼ç¼ºä¹å–®ä¸€çš„åŸºæº–çœŸå¯¦å€¼å’Œç ”ç©¶å“è³ªçš„å¤šç¶­æ€§è³ªï¼Œè©•ä¼°é€™äº›å ±å‘Šä»ç„¶å…·æœ‰æŒ‘æˆ°æ€§ã€‚æœ€è¿‘çš„åŸºæº–æ¸¬è©¦æå‡ºäº†ä¸åŒçš„æ–¹æ³•è«–ï¼Œä½†å®ƒå€‘å—åˆ°ã€Œåˆæˆå¹»è±¡ã€çš„å½±éŸ¿ï¼Œå…¶ä¸­å¼·å¤§çš„è¡¨é¢æµæš¢æ€§å’Œå¼•ç”¨å°é½å¯èƒ½æ©è“‹æ½›åœ¨çš„äº‹å¯¦å’Œæ¨ç†ç¼ºé™·ã€‚æˆ‘å€‘é€éå¼•å…¥è·¨è¶Šå››å€‹å‚ç›´é ˜åŸŸçš„åˆ†é¡æ³•ä¾†æè¿°é€™ä¸€å·®è·ï¼Œè©²åˆ†é¡æ³•æ­ç¤ºäº†ä¸€å€‹é—œéµçš„èƒ½åŠ›ä¸åŒ¹é…ï¼šéœæ…‹è©•ä¼°å™¨æœ¬è³ªä¸Šç¼ºä¹è©•ä¼°æ™‚é–“æœ‰æ•ˆæ€§å’Œäº‹å¯¦æ­£ç¢ºæ€§æ‰€éœ€çš„å·¥å…·ä½¿ç”¨èƒ½åŠ›ã€‚ç‚ºäº†è§£æ±ºé€™å€‹å•é¡Œï¼Œæˆ‘å€‘æå‡ºäº† DREAMï¼ˆDeep Research Evaluation with Agentic Metricsï¼‰ï¼Œé€™æ˜¯ä¸€å€‹é€éä½¿è©•ä¼°æœ¬èº«å…·æœ‰ä»£ç†ç‰¹æ€§ä¾†å¯¦ç¾èƒ½åŠ›å°ç­‰åŸå‰‡çš„æ¡†æ¶ã€‚DREAM é€éçµåˆæŸ¥è©¢ç„¡é—œæŒ‡æ¨™èˆ‡ç”±å·¥å…·èª¿ç”¨ä»£ç†ç”Ÿæˆçš„è‡ªé©æ‡‰æŒ‡æ¨™çš„è©•ä¼°å”è­°ä¾†æ§‹é€ è©•ä¼°ï¼Œå¾è€Œå¯¦ç¾æ™‚é–“æ„ŸçŸ¥è¦†è“‹ã€åŸºæ–¼äº‹å¯¦çš„é©—è­‰å’Œç³»çµ±æ€§æ¨ç†æ¢æ¸¬ã€‚å—æ§è©•ä¼°è¡¨æ˜ DREAM å°äº‹å¯¦å’Œæ™‚é–“è¡°è®Šçš„æ•æ„Ÿåº¦é¡¯è‘—é«˜æ–¼ç¾æœ‰åŸºæº–æ¸¬è©¦ï¼Œæä¾›äº†ä¸€å€‹å¯æ“´å±•çš„ã€ç„¡åƒè€ƒçš„è©•ä¼°ç¯„å¼ã€‚</p>
  
  <div class="abstract-en">Deep Research Agents generate analyst-grade reports, yet evaluating them remains challenging due to the absence of a single ground truth and the multidimensional nature of research quality. Recent benchmarks propose distinct methodologies, yet they suffer from the Mirage of Synthesis, where strong surface-level fluency and citation alignment can obscure underlying factual and reasoning defects. We characterize this gap by introducing a taxonomy across four verticals that exposes a critical capability mismatch: static evaluators inherently lack the tool-use capabilities required to assess temporal validity and factual correctness. To address this, we propose DREAM (Deep Research Evaluation with Agentic Metrics), a framework that instantiates the principle of capability parity by making evaluation itself agentic. DREAM structures assessment through an evaluation protocol combining query-agnostic metrics with adaptive metrics generated by a tool-calling agent, enabling temporally aware coverage, grounded verification, and systematic reasoning probes. Controlled evaluations demonstrate DREAM is significantly more sensitive to factual and temporal decay than existing benchmarks, offering a scalable, reference-free evaluation paradigm.</div>
  
</div>

<!-- Full translated content -->
<div class="paper-body">
  
    <p style="color:var(--text-muted);font-style:italic;">å…¨æ–‡ç¿»è­¯å°šæœªç”Ÿæˆã€‚</p>
  
</div>


  </main>

  <footer class="site-footer">
    <div class="container">
      <p>æ¯æ—¥è‡ªå‹•æŠ“å– <a href="https://huggingface.co/papers" target="_blank">HuggingFace Daily Papers</a>ï¼Œä»¥ Claude AI ç¿»è­¯ç‚ºç¹é«”ä¸­æ–‡ã€‚</p>
    </div>
  </footer>
</body>
</html>