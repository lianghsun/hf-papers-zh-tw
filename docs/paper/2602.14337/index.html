<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>LongCLI-Benchï¼šé•·åºåˆ—ä»£ç†ç¨‹å¼è¨­è¨ˆåœ¨å‘½ä»¤è¡Œä»‹é¢ä¸­çš„åˆæ­¥åŸºæº–æ¸¬è©¦èˆ‡ç ”ç©¶ â€” HF Papers ç¹ä¸­</title>
  <link rel="stylesheet" href="../../assets/style.css">
  
</head>
<body>
  <header class="site-header">
    <div class="container">
      <a href="../../index.html" class="site-logo">ğŸ“„ HF Papers ç¹ä¸­</a>
      <nav>
        <a href="../../index.html">é¦–é </a>
        <a href="https://huggingface.co/papers" target="_blank" rel="noopener">HuggingFace</a>
      </nav>
    </div>
  </header>

  <main class="container">
    

<div class="paper-page-header">
  <a href="../../2026-02-25/index.html" style="font-size:0.85rem;color:var(--text-muted);">
    â† 2026-02-25 è«–æ–‡åˆ—è¡¨
  </a>
  <h1 style="margin-top:0.75rem;">LongCLI-Benchï¼šé•·åºåˆ—ä»£ç†ç¨‹å¼è¨­è¨ˆåœ¨å‘½ä»¤è¡Œä»‹é¢ä¸­çš„åˆæ­¥åŸºæº–æ¸¬è©¦èˆ‡ç ”ç©¶</h1>
  
  <div class="en-title">LongCLI-Bench: A Preliminary Benchmark and Study for Long-horizon Agentic Programming in Command-Line Interfaces</div>
  

  <div class="paper-meta">
    
    <span>Yukang Feng, Jianwen Sun, Zelai Yang, Jiaxin Ai, Chuanhao Li, Zizhen Li, Fanrui Zhang, Kang He, Rui Ma, Jifan Lin, Jie Sun, Yang Xiao, Sizhuo Zhou, Wenxiao Wu, Yiming Liu, Pengfei Liu, Yu Qiao, Shenglin Zhang, Kaipeng Zhang</span>
    
    <span>arXiv: <a href="https://arxiv.org/abs/2602.14337" target="_blank">2602.14337</a></span>
    
    <span style="color:var(--text-muted);font-size:0.8rem;">
      ä¾†æºï¼šPDF + DotsOCR
    </span>
    
  </div>

  <div class="paper-links">
    <a href="https://arxiv.org/pdf/2602.14337" target="_blank" rel="noopener" class="btn btn-primary">PDF åŸæ–‡</a>
    <a href="https://arxiv.org/abs/2602.14337" target="_blank" rel="noopener" class="btn btn-outline">arXiv</a>
    <a href="https://huggingface.co/papers/2602.14337" target="_blank" rel="noopener" class="btn btn-outline">HF é é¢</a>
  </div>

  <div class="tags">
    <span class="tag domain">Code</span>
    <span class="tag method">Agent</span><span class="tag method">LLM</span><span class="tag method">Planning</span>
    <span class="tag task">Long-horizon Programming</span><span class="tag task">Command-Line Task Execution</span><span class="tag task">Software Engineering</span>
    
  </div>
</div>

<!-- Abstract -->
<div class="abstract-box">
  <h2>æ‘˜è¦</h2>
  <p># è«–æ–‡æ‘˜è¦ç¿»è­¯

è¿‘æœŸ AI è¼”åŠ©ç¨‹å¼è¨­è¨ˆçš„é€²å±•ä½¿å¾—ä»£ç†èƒ½å¤ é€éå‘½ä»¤åˆ—ä»‹é¢åŸ·è¡Œè¤‡é›œçš„å·¥ä½œæµç¨‹ï¼Œç„¶è€Œç¾æœ‰çš„åŸºæº–æ¸¬è©¦å—é™æ–¼çŸ­æœŸä»»å‹™ç¯„åœã€GitHub çˆ¬èŸ²çš„è³‡æ–™æ±¡æŸ“ï¼Œä»¥åŠç¼ºä¹ç´°ç²’åº¦çš„è©•ä¼°æŒ‡æ¨™ï¼Œç„¡æ³•åš´æ ¼è©•ä¼°ç¾å¯¦è»Ÿé«”å·¥ç¨‹ä¸­å¿…éœ€çš„é•·æœŸè¦åŠƒå’ŒåŸ·è¡Œèƒ½åŠ›ã€‚ç‚ºäº†è§£æ±ºé€™äº›å•é¡Œï¼Œæˆ‘å€‘æ¨å‡º LongCLI-Benchï¼Œä¸€å€‹å…¨é¢çš„åŸºæº–æ¸¬è©¦ï¼Œæ—¨åœ¨è©•ä¼°ä»£ç†åœ¨é•·æœŸã€ç¾å¯¦ä»»å‹™ä¸­çš„èƒ½åŠ›ã€‚æˆ‘å€‘å¾è¶…é 1,000 å€‹é›»è…¦ç§‘å­¸èª²ç¨‹ä½œæ¥­å’Œç¾å¯¦å·¥ä½œæµç¨‹ä¸­ç²¾å¿ƒæŒ‘é¸äº† 20 å€‹é«˜å“è³ªã€é•·æœŸä»»å‹™ï¼Œæ¶µè“‹å››å€‹å·¥ç¨‹é¡åˆ¥ï¼šå¾é›¶é–‹å§‹ã€åŠŸèƒ½æ·»åŠ ã€è‡­èŸ²ä¿®å¾©å’Œé‡æ§‹ã€‚æˆ‘å€‘ç‚º LongCLI-Bench æå‡ºäº†é›™é›†æ¸¬è©¦å”è­°ï¼Œè©²å”è­°æ¸¬é‡éœ€æ±‚æ»¿è¶³åº¦ï¼ˆå¤±æ•—è½‰é€šéï¼‰å’Œè¿´æ­¸é¿å…ï¼ˆé€šéè½‰é€šéï¼‰ï¼Œä¸¦ç´å…¥æ­¥é©Ÿç´šè©•åˆ†ä»¥ç²¾ç¢ºå®šä½åŸ·è¡Œå¤±æ•—ã€‚å»£æ³›çš„å¯¦é©—é¡¯ç¤ºï¼Œå³ä½¿æ˜¯æœ€å…ˆé€²çš„ä»£ç†åœ¨ LongCLI-Bench ä¸Šçš„é€šéç‡ä¹Ÿä½æ–¼ 20%ã€‚æ­¥é©Ÿç´šåˆ†æé€²ä¸€æ­¥è¡¨æ˜ï¼Œå¤§å¤šæ•¸ä»»å‹™åœ¨å®Œæˆåº¦ä¸è¶³ 30% æ™‚åœæ»¯ï¼Œçªé¡¯å‡ºé—œéµå¤±æ•—å¾€å¾€ç™¼ç”Ÿåœ¨æ—©æœŸéšæ®µã€‚å„˜ç®¡è‡ªæˆ‘ä¿®æ­£èƒ½å¤ å¸¶ä¾†é‚Šéš›æ”¶ç›Šï¼Œä½†é€éè¨ˆç•«æ³¨å…¥å’Œäº’å‹•å¼æŒ‡å°çš„äºº-ä»£ç†å”ä½œèƒ½ç”¢ç”Ÿé¡¯è‘—æ›´é«˜çš„æ”¹é€²ã€‚é€™äº›çµæœå¼·èª¿ï¼Œæœªä¾†çš„ç ”ç©¶å¿…é ˆå¼·èª¿é–‹ç™¼å”åŒäºº-ä»£ç†å·¥ä½œæµç¨‹ï¼ŒåŒæ™‚æ¨é€²ä»£ç†çš„è¦åŠƒå’ŒåŸ·è¡Œèƒ½åŠ›ï¼Œä»¥å…‹æœé•·æœŸä»»å‹™æ€§èƒ½ä¸­çš„é—œéµæŒ‘æˆ°ã€‚</p>
  
  <div class="abstract-en">Recent advances in AI-assisted programming have empowered agents to execute complex workflows via command-line interfaces, however, existing benchmarks are limited by short task horizons, data contamination from GitHub scraping, and a lack of fine-grained evaluation metrics, fail to rigorously evaluate the long-horizon planning and execution capabilities essential for realistic software engineering. To address these gaps, we introduce LongCLI-Bench, a comprehensive benchmark designed to evaluate agentic capabilities across long-horizon, realistic tasks. We curated 20 high-quality, long-horizon tasks from over 1,000 computer science assignments and real-world workflows, covering four engineering categories: from scratch, feature addition, bug fixing, and refactoring. We propose a dual-set testing protocol for LongCLI-Bench, which measures requirement fulfillment (fail-to-pass) and regression avoidance (pass-to-pass), and incorporates step-level scoring to pinpoint execution failures. Extensive experiments reveal that even state-of-the-art agents achieve pass rates below 20% in LongCLI-Bench. Step-level analysis further indicates that the majority of tasks stall at less than 30% completion, highlighting that critical failures often occur in the early stages. Although self-correction offers marginal gains, human-agent collaboration through plan injection and interactive guidance yields significantly higher improvements. These results highlight that future research must emphasize the development of synergistic human-agent workflows alongside advances in agents&#39; planning and execution capabilities to overcome key challenges in long-horizon task performance.</div>
  
</div>

<!-- Full translated content -->
<div class="paper-body">
  
    <p style="color:var(--text-muted);font-style:italic;">å…¨æ–‡ç¿»è­¯å°šæœªç”Ÿæˆã€‚</p>
  
</div>


  </main>

  <footer class="site-footer">
    <div class="container">
      <p>æ¯æ—¥è‡ªå‹•æŠ“å– <a href="https://huggingface.co/papers" target="_blank">HuggingFace Daily Papers</a>ï¼Œä»¥ Claude AI ç¿»è­¯ç‚ºç¹é«”ä¸­æ–‡ã€‚</p>
    </div>
  </footer>
</body>
</html>